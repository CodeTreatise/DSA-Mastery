# LRU Cache Implementation

> **The classic design interview question: O(1) get and put with LRU eviction.**
>
> Pattern: HashMap + Doubly Linked List = O(1) for all operations.

---

## ðŸŽ¯ Pattern Recognition

<details>
<summary><strong>How to Identify This Pattern</strong></summary>

**Problem statement signals:**
- "Design a cache with O(1) get and put"
- "Evict the least recently used item when full"
- "Fixed capacity cache"
- "Most recently used should be kept"

**Key constraints:**
```
get(key): Return value if exists, mark as recently used
put(key, value): Insert/update, evict LRU if over capacity
Both operations must be O(1)
```

</details>

---

## âœ… When to Use

| Requirement | Why This Design |
|-------------|-----------------|
| O(1) get by key | HashMap provides O(1) lookup |
| O(1) update recency | Doubly linked list: O(1) remove/insert |
| O(1) eviction | Tail of DLL is LRU, O(1) to remove |
| Track usage order | DLL maintains order |

---

## âŒ Why Other Approaches Fail

| Approach | Problem |
|----------|---------|
| Array + HashMap | Moving elements is O(n) |
| Singly Linked List | Finding prev node is O(n) |
| Just HashMap | No ordering |
| Just Linked List | Finding by key is O(n) |
| Heap/Priority Queue | Update priority is O(log n) |

---

## ðŸ“ How It Works

### The Data Structure

```
HashMap: key â†’ Node (O(1) access to any node)

Doubly Linked List: ordered by recency
    HEAD â†â†’ [MRU] â†â†’ [recent] â†â†’ [old] â†â†’ [LRU] â†â†’ TAIL
           (most recent)              (least recent)

Dummy HEAD and TAIL simplify edge cases!
```

### Operations Visualized

**get(key):**
```
1. Look up node in HashMap: O(1)
2. If found:
   a. Remove node from current position: O(1)
   b. Insert right after HEAD (most recent): O(1)
   c. Return value
3. If not found: return -1
```

**put(key, value):**
```
1. If key exists:
   a. Update value
   b. Move to front (like get)
2. If key doesn't exist:
   a. Create new node
   b. Add to HashMap
   c. Insert after HEAD
   d. If over capacity:
      - Remove node before TAIL (LRU)
      - Delete from HashMap
```

---

## ðŸ’» Complete Implementation

**Python:**
```python
class ListNode:
    """Doubly linked list node."""
    def __init__(self, key: int = 0, val: int = 0):
        self.key = key  # Need key to remove from HashMap on eviction!
        self.val = val
        self.prev = None
        self.next = None


class LRUCache:
    """
    LRU Cache with O(1) get and put.
    
    Data structures:
    - HashMap: key â†’ Node for O(1) lookup
    - Doubly Linked List: ordered by recency (HEAD = MRU, TAIL = LRU)
    
    Time: O(1) for both get and put
    Space: O(capacity)
    """
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}  # key â†’ ListNode
        
        # Dummy head and tail for easier edge case handling
        self.head = ListNode()
        self.tail = ListNode()
        self.head.next = self.tail
        self.tail.prev = self.head
    
    def _remove(self, node: ListNode) -> None:
        """Remove node from its current position in the list."""
        node.prev.next = node.next
        node.next.prev = node.prev
    
    def _add_to_front(self, node: ListNode) -> None:
        """Add node right after head (most recently used position)."""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def _move_to_front(self, node: ListNode) -> None:
        """Move existing node to front (mark as most recently used)."""
        self._remove(node)
        self._add_to_front(node)
    
    def get(self, key: int) -> int:
        """
        Get value by key.
        
        Returns value if found (and marks as recently used).
        Returns -1 if not found.
        """
        if key not in self.cache:
            return -1
        
        node = self.cache[key]
        self._move_to_front(node)  # Mark as recently used
        return node.val
    
    def put(self, key: int, value: int) -> None:
        """
        Insert or update key-value pair.
        
        If key exists: update value and move to front.
        If key doesn't exist: add new node, evict LRU if over capacity.
        """
        if key in self.cache:
            # Update existing
            node = self.cache[key]
            node.val = value
            self._move_to_front(node)
        else:
            # Add new
            node = ListNode(key, value)
            self.cache[key] = node
            self._add_to_front(node)
            
            # Evict if over capacity
            if len(self.cache) > self.capacity:
                lru_node = self.tail.prev  # Node just before tail
                self._remove(lru_node)
                del self.cache[lru_node.key]  # Why we store key in node!


# Example usage
cache = LRUCache(2)
cache.put(1, 1)
cache.put(2, 2)
print(cache.get(1))    # 1 (also moves key 1 to front)
cache.put(3, 3)        # Evicts key 2 (LRU)
print(cache.get(2))    # -1 (not found)
cache.put(4, 4)        # Evicts key 1
print(cache.get(1))    # -1 (not found)
print(cache.get(3))    # 3
print(cache.get(4))    # 4
```

**JavaScript:**
```javascript
class ListNode {
    constructor(key = 0, val = 0) {
        this.key = key;
        this.val = val;
        this.prev = null;
        this.next = null;
    }
}

class LRUCache {
    constructor(capacity) {
        this.capacity = capacity;
        this.cache = new Map();
        
        // Dummy head and tail
        this.head = new ListNode();
        this.tail = new ListNode();
        this.head.next = this.tail;
        this.tail.prev = this.head;
    }
    
    _remove(node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }
    
    _addToFront(node) {
        node.prev = this.head;
        node.next = this.head.next;
        this.head.next.prev = node;
        this.head.next = node;
    }
    
    _moveToFront(node) {
        this._remove(node);
        this._addToFront(node);
    }
    
    get(key) {
        if (!this.cache.has(key)) {
            return -1;
        }
        
        const node = this.cache.get(key);
        this._moveToFront(node);
        return node.val;
    }
    
    put(key, value) {
        if (this.cache.has(key)) {
            const node = this.cache.get(key);
            node.val = value;
            this._moveToFront(node);
        } else {
            const node = new ListNode(key, value);
            this.cache.set(key, node);
            this._addToFront(node);
            
            if (this.cache.size > this.capacity) {
                const lruNode = this.tail.prev;
                this._remove(lruNode);
                this.cache.delete(lruNode.key);
            }
        }
    }
}

// Example usage
const cache = new LRUCache(2);
cache.put(1, 1);
cache.put(2, 2);
console.log(cache.get(1));    // 1
cache.put(3, 3);              // Evicts key 2
console.log(cache.get(2));    // -1
cache.put(4, 4);              // Evicts key 1
console.log(cache.get(1));    // -1
console.log(cache.get(3));    // 3
console.log(cache.get(4));    // 4
```

---

## ðŸ” Walkthrough

```
Capacity = 2

Step 1: put(1, 1)
  HashMap: {1: Node(1,1)}
  List: HEAD â†â†’ [1,1] â†â†’ TAIL

Step 2: put(2, 2)
  HashMap: {1: Node(1,1), 2: Node(2,2)}
  List: HEAD â†â†’ [2,2] â†â†’ [1,1] â†â†’ TAIL
                 MRU        LRU

Step 3: get(1) â†’ returns 1, moves to front
  List: HEAD â†â†’ [1,1] â†â†’ [2,2] â†â†’ TAIL
                 MRU        LRU

Step 4: put(3, 3) â†’ over capacity, evict LRU (key 2)
  HashMap: {1: Node(1,1), 3: Node(3,3)}
  List: HEAD â†â†’ [3,3] â†â†’ [1,1] â†â†’ TAIL

Step 5: get(2) â†’ returns -1 (evicted)

Step 6: put(4, 4) â†’ over capacity, evict LRU (key 1)
  HashMap: {3: Node(3,3), 4: Node(4,4)}
  List: HEAD â†â†’ [4,4] â†â†’ [3,3] â†â†’ TAIL
```

---

## âš¡ Complexity Analysis

| Operation | Time | Space |
|-----------|------|-------|
| `__init__` | O(1) | O(capacity) |
| `get(key)` | O(1) | O(1) |
| `put(key, value)` | O(1) | O(1) |
| **Overall Space** | - | O(capacity) |

**Why O(1) for all operations?**
- HashMap: O(1) lookup by key
- Doubly Linked List: O(1) insert/remove at known position
- We always have direct access to nodes via HashMap

---

## âš ï¸ Common Mistakes

### 1. Not Storing Key in Node

```python
# âŒ Wrong: No way to delete from HashMap on eviction
class ListNode:
    def __init__(self, val):
        self.val = val  # Only value!

# When evicting:
lru_node = self.tail.prev
self._remove(lru_node)
del self.cache[???]  # Don't know the key!

# âœ… Correct: Store key in node
class ListNode:
    def __init__(self, key, val):
        self.key = key  # Need this for eviction!
        self.val = val
```

### 2. Wrong Order in Doubly Linked List Updates

```python
# âŒ Wrong: Order matters for pointer updates!
def _add_to_front(self, node):
    node.next = self.head.next
    self.head.next = node  # Breaks the chain before updating prev!
    node.prev = self.head
    node.next.prev = node

# âœ… Correct: Update all pointers carefully
def _add_to_front(self, node):
    node.prev = self.head
    node.next = self.head.next
    self.head.next.prev = node  # Update old first's prev
    self.head.next = node       # Now update head's next
```

### 3. Forgetting Dummy Nodes

```python
# âŒ Wrong: No dummy nodes
def _remove(self, node):
    if node.prev:  # Extra null checks everywhere
        node.prev.next = node.next
    if node.next:
        node.next.prev = node.prev

# âœ… Correct: Dummy head/tail eliminate edge cases
def _remove(self, node):
    node.prev.next = node.next  # Always works!
    node.next.prev = node.prev
```

### 4. Not Moving to Front on Put (Update)

```python
# âŒ Wrong: Only move on get
def put(self, key, value):
    if key in self.cache:
        self.cache[key].val = value  # Updated but not moved!

# âœ… Correct: Also move on put
def put(self, key, value):
    if key in self.cache:
        node = self.cache[key]
        node.val = value
        self._move_to_front(node)  # Mark as recently used!
```

---

## ðŸŽ¤ Interview Communication

**Opening:**
> "For O(1) get and put with LRU eviction, I need two data structures working together:
> 1. **HashMap** for O(1) key lookup
> 2. **Doubly Linked List** for O(1) insertion and removal by position
> 
> The HashMap maps keys to list nodes, and the list maintains order by recency."

**Explain the design:**
> "I'll use dummy head and tail nodes to simplify edge cases. The most recently used item is right after the head, and the least recently used is right before the tail. On each access, I move the node to the front. On eviction, I remove from the tail."

**Key insight to mention:**
> "I need to store the key in each list node. When evicting, I have the node but need to also delete from the HashMap, so I need the key."

---

## ðŸ”„ Variations

| Variation | Change | When Used |
|-----------|--------|-----------|
| **LFU Cache** | Evict least *frequently* used | When access count matters more |
| **TTL Cache** | Items expire after time | Web caching |
| **Bounded LRU** | Size-based eviction | Memory limits |
| **Thread-safe LRU** | Add locks | Concurrent access |

---

## ðŸ“ Practice Problems

| Problem | Difficulty | Pattern |
|---------|------------|---------|
| [LRU Cache](https://leetcode.com/problems/lru-cache/) | Medium | HashMap + DLL |
| [LFU Cache](https://leetcode.com/problems/lfu-cache/) | Hard | Double HashMap + DLL |
| [Design HashMap](https://leetcode.com/problems/design-hashmap/) | Easy | Array of buckets |

---

## â±ï¸ Time Estimates

| Activity | Time | Notes |
|----------|------|-------|
| Understand the design | 15-20 min | HashMap + DLL concept |
| Implement from scratch | 20-25 min | Interview target |
| Debug pointer issues | 5-10 min | Common stumbling block |
| Explain and optimize | 5-10 min | Communication practice |

---

> **ðŸ’¡ Key Insight:** The magic is that HashMap gives O(1) access to any node, and with that direct reference, doubly linked list operations (remove, insert at ends) are also O(1). Neither data structure alone can do this!

> **ðŸ”— Related:** [Cache Fundamentals](./2.1-Cache-Fundamentals.md) | [LFU Cache](./2.3-LFU-Cache.md)

---

**Next:** [LFU Cache â†’](./2.3-LFU-Cache.md)
