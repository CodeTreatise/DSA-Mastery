# LRU Cache (LeetCode 146)

> **Medium** | Design a data structure that follows LRU (Least Recently Used) cache constraints with O(1) get and put operations.

This is one of the most important design problems in interviews. It combines Hash Map with Doubly Linked List to achieve O(1) for all operations.

---

## üéØ Pattern Recognition

<details>
<summary><strong>Problem Signals</strong></summary>

**Keywords indicating this pattern:**
- "LRU Cache"
- "Least recently used"
- "Fixed capacity with eviction"
- "O(1) get and put"
- "Track access order"

**Problem classification:**
```
Category: Design Problem
Data Structures: Hash Map + Doubly Linked List
Key Insight: Hash for O(1) lookup, DLL for O(1) order management
```

</details>

---

## üìã Problem Statement

**LeetCode 146:** [LRU Cache](https://leetcode.com/problems/lru-cache/)

```
Design a data structure that follows the constraints of a 
Least Recently Used (LRU) cache.

Implement the LRUCache class:
- LRUCache(int capacity) - Initialize with positive capacity
- int get(int key) - Return value if key exists, else -1
  - Mark as recently used
- void put(int key, int value) - Update or insert
  - If capacity exceeded, evict least recently used
  - Mark as recently used

The functions get and put must each run in O(1) average time.

Example:
LRUCache cache = new LRUCache(2);
cache.put(1, 1);       // cache is {1=1}
cache.put(2, 2);       // cache is {1=1, 2=2}
cache.get(1);          // return 1, cache is {2=2, 1=1}
cache.put(3, 3);       // evict key 2, cache is {1=1, 3=3}
cache.get(2);          // return -1 (not found)
cache.put(4, 4);       // evict key 1, cache is {3=3, 4=4}
cache.get(1);          // return -1 (not found)
cache.get(3);          // return 3
cache.get(4);          // return 4

Constraints:
- 1 <= capacity <= 3000
- 0 <= key <= 10^4
- 0 <= value <= 10^5
- At most 2 * 10^5 calls to get and put
```

---

## ‚úÖ When to Use This Design

- Fixed-size cache with eviction policy
- Need to track recency of access
- O(1) operations required
- Memory-constrained scenarios

---

## ‚ùå When NOT to Use

| Scenario | Why Not | Use Instead |
|----------|---------|-------------|
| Need LFU (frequency-based) | LRU tracks recency, not frequency | LFU Cache design |
| Variable capacity | Fixed capacity assumed | Dynamic structure |
| Need TTL-based expiry | LRU doesn't track time | Time-based eviction |
| Simple key-value (no eviction) | Overkill | Plain HashMap |
| Thread-safe required | Basic design isn't concurrent | ConcurrentHashMap + locks |

---

## üîó Concept Map

<details>
<summary><strong>Prerequisites & Next Steps</strong></summary>

**Before this, understand:**
- [Hash Map Operations](../02-Hash-Map-Set/2.1-Hash-Map-Operations.md)
- Doubly Linked List operations
- [Design HashMap (LC 706)](./8.2-Design-HashMap-LC706.md)

**After mastering this:**
- [LFU Cache (LC 460)](https://leetcode.com/problems/lfu-cache/) - Frequency-based eviction
- [All O'one Data Structure (LC 432)](https://leetcode.com/problems/all-oone-data-structure/)
- Operating system page replacement algorithms

**Key insight:**
- HashMap alone: O(1) lookup but no order
- DLL alone: O(1) reorder but O(n) lookup
- Combined: O(1) for everything

</details>

---

## üìê Solution Design

### Why Hash Map + Doubly Linked List?

| Requirement | Hash Map Alone | DLL Alone | Hash Map + DLL |
|-------------|---------------|-----------|----------------|
| O(1) lookup | ‚úÖ | ‚ùå O(n) | ‚úÖ |
| O(1) insert | ‚úÖ | ‚úÖ | ‚úÖ |
| O(1) delete | ‚úÖ | ‚ùå O(n) to find | ‚úÖ |
| O(1) move to front | ‚ùå No order | ‚úÖ | ‚úÖ |
| O(1) find LRU | ‚ùå No order | ‚úÖ (tail) | ‚úÖ |

**Neither alone works!** Combined: Hash Map gives O(1) lookup of nodes, DLL gives O(1) reordering.

### Data Structure Design

```
Hash Map: key ‚Üí Node reference
Doubly Linked List: Most Recent ‚Üê‚Üí ... ‚Üê‚Üí Least Recent

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Hash Map                                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ ‚îÇ key=1 ‚Üí Node(1, "A")                  ‚îÇ                  ‚îÇ
‚îÇ ‚îÇ key=2 ‚Üí Node(2, "B")                  ‚îÇ                  ‚îÇ
‚îÇ ‚îÇ key=3 ‚Üí Node(3, "C")                  ‚îÇ                  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ Doubly Linked List (MRU ‚Üê‚Üí LRU)                            ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ ‚îÇ HEAD ‚îÇ‚Üê‚Üí‚îÇ Node(3,C)‚îÇ‚Üê‚Üí‚îÇ Node(1,A)‚îÇ‚Üê‚Üí‚îÇ Node(2,B)‚îÇ‚Üê‚Üí‚îÇTAIL‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ  (dummy)     Most Recent                 Least Recent (dummy)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

On get(1):
1. Look up in Hash Map ‚Üí O(1)
2. Move Node(1,A) to front ‚Üí O(1)

On put(4, D) when at capacity:
1. Remove Node(2,B) from tail ‚Üí O(1)
2. Remove key=2 from Hash Map ‚Üí O(1)
3. Add Node(4,D) to front ‚Üí O(1)
4. Add key=4 to Hash Map ‚Üí O(1)
```

### Operation Flow

**get(key):**
```
1. If key not in hash map ‚Üí return -1
2. Get node from hash map
3. Move node to front of DLL
4. Return node.value
```

**put(key, value):**
```
1. If key exists:
   a. Update node's value
   b. Move node to front
2. Else:
   a. If at capacity, evict LRU (tail)
   b. Create new node
   c. Add to front of DLL
   d. Add to hash map
```

---

## üíª Code Implementation

### Python - Clean Implementation

```python
class ListNode:
    """Doubly linked list node."""
    def __init__(self, key: int = 0, val: int = 0):
        self.key = key
        self.val = val
        self.prev = None
        self.next = None

class LRUCache:
    """
    LRU Cache using Hash Map + Doubly Linked List.
    
    Hash Map: key ‚Üí Node (O(1) lookup)
    DLL: maintains access order (O(1) reorder)
    
    Time: O(1) for get and put
    Space: O(capacity) for cache
    """
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}  # key ‚Üí Node
        
        # Dummy head and tail for easier edge case handling
        self.head = ListNode()  # Most recently used (MRU)
        self.tail = ListNode()  # Least recently used (LRU)
        self.head.next = self.tail
        self.tail.prev = self.head
    
    def _remove(self, node: ListNode) -> None:
        """Remove node from current position in DLL."""
        node.prev.next = node.next
        node.next.prev = node.prev
    
    def _add_to_front(self, node: ListNode) -> None:
        """Add node right after head (most recently used position)."""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def _move_to_front(self, node: ListNode) -> None:
        """Move existing node to front (mark as recently used)."""
        self._remove(node)
        self._add_to_front(node)
    
    def get(self, key: int) -> int:
        """
        Get value for key.
        Returns -1 if not found.
        Marks key as recently used.
        """
        if key not in self.cache:
            return -1
        
        node = self.cache[key]
        self._move_to_front(node)  # Mark as recently used
        return node.val
    
    def put(self, key: int, value: int) -> None:
        """
        Insert or update key-value pair.
        Evicts LRU item if at capacity.
        Marks key as recently used.
        """
        if key in self.cache:
            # Update existing key
            node = self.cache[key]
            node.val = value
            self._move_to_front(node)
        else:
            # Add new key
            if len(self.cache) >= self.capacity:
                # Evict LRU (node before tail)
                lru = self.tail.prev
                self._remove(lru)
                del self.cache[lru.key]
            
            # Create and add new node
            node = ListNode(key, value)
            self.cache[key] = node
            self._add_to_front(node)


# Example trace:
# cache = LRUCache(2)
# 
# put(1, 1):
#   cache = {1: Node(1,1)}
#   DLL: HEAD ‚Üî Node(1,1) ‚Üî TAIL
#
# put(2, 2):
#   cache = {1: Node(1,1), 2: Node(2,2)}
#   DLL: HEAD ‚Üî Node(2,2) ‚Üî Node(1,1) ‚Üî TAIL
#
# get(1):
#   Move Node(1,1) to front
#   DLL: HEAD ‚Üî Node(1,1) ‚Üî Node(2,2) ‚Üî TAIL
#   Return 1
#
# put(3, 3):
#   At capacity! Evict LRU = Node(2,2)
#   cache = {1: Node(1,1), 3: Node(3,3)}
#   DLL: HEAD ‚Üî Node(3,3) ‚Üî Node(1,1) ‚Üî TAIL
```

### Python - Using OrderedDict

```python
from collections import OrderedDict

class LRUCache:
    """
    LRU Cache using Python's OrderedDict.
    
    OrderedDict maintains insertion order and provides
    move_to_end() for O(1) reordering.
    
    Simpler but less portable to other languages.
    """
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = OrderedDict()
    
    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        
        # Move to end (most recently used)
        self.cache.move_to_end(key)
        return self.cache[key]
    
    def put(self, key: int, value: int) -> None:
        if key in self.cache:
            # Update and move to end
            self.cache.move_to_end(key)
            self.cache[key] = value
        else:
            # Check capacity
            if len(self.cache) >= self.capacity:
                # Remove first item (LRU)
                self.cache.popitem(last=False)
            
            # Add new item (goes to end)
            self.cache[key] = value


# Note: In interviews, implementing DLL is often expected
# to demonstrate understanding. OrderedDict is great for
# production code but may not satisfy interviewers.
```

### JavaScript - Hash Map + Doubly Linked List

```javascript
class ListNode {
    constructor(key = 0, val = 0) {
        this.key = key;
        this.val = val;
        this.prev = null;
        this.next = null;
    }
}

class LRUCache {
    /**
     * @param {number} capacity
     */
    constructor(capacity) {
        this.capacity = capacity;
        this.cache = new Map();
        
        // Dummy head and tail
        this.head = new ListNode();
        this.tail = new ListNode();
        this.head.next = this.tail;
        this.tail.prev = this.head;
    }
    
    /**
     * Remove node from its current position.
     * @param {ListNode} node
     */
    _remove(node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }
    
    /**
     * Add node right after head.
     * @param {ListNode} node
     */
    _addToFront(node) {
        node.prev = this.head;
        node.next = this.head.next;
        this.head.next.prev = node;
        this.head.next = node;
    }
    
    /**
     * Move node to front (most recently used).
     * @param {ListNode} node
     */
    _moveToFront(node) {
        this._remove(node);
        this._addToFront(node);
    }
    
    /**
     * Get value for key.
     * @param {number} key
     * @return {number}
     */
    get(key) {
        if (!this.cache.has(key)) {
            return -1;
        }
        
        const node = this.cache.get(key);
        this._moveToFront(node);
        return node.val;
    }
    
    /**
     * Put key-value pair in cache.
     * @param {number} key
     * @param {number} value
     * @return {void}
     */
    put(key, value) {
        if (this.cache.has(key)) {
            const node = this.cache.get(key);
            node.val = value;
            this._moveToFront(node);
        } else {
            if (this.cache.size >= this.capacity) {
                // Evict LRU
                const lru = this.tail.prev;
                this._remove(lru);
                this.cache.delete(lru.key);
            }
            
            const node = new ListNode(key, value);
            this.cache.set(key, node);
            this._addToFront(node);
        }
    }
}
```

### JavaScript - Using Map (ES6)

```javascript
class LRUCache {
    /**
     * Using Map which maintains insertion order.
     * @param {number} capacity
     */
    constructor(capacity) {
        this.capacity = capacity;
        this.cache = new Map();
    }
    
    get(key) {
        if (!this.cache.has(key)) {
            return -1;
        }
        
        // Move to end: delete and re-add
        const value = this.cache.get(key);
        this.cache.delete(key);
        this.cache.set(key, value);
        return value;
    }
    
    put(key, value) {
        if (this.cache.has(key)) {
            this.cache.delete(key);
        } else if (this.cache.size >= this.capacity) {
            // Delete first key (LRU)
            const firstKey = this.cache.keys().next().value;
            this.cache.delete(firstKey);
        }
        this.cache.set(key, value);
    }
}

// Note: This works in JavaScript because Map maintains
// insertion order. In interviews, show DLL implementation.
```

---

## ‚ö° Complexity Analysis

| Operation | Time | Space |
|-----------|------|-------|
| get | O(1) | - |
| put | O(1) | - |
| Overall Space | - | O(capacity) |

**Why O(1)?**
- Hash Map lookup: O(1) average
- DLL node removal: O(1) - just pointer updates
- DLL add to front: O(1) - just pointer updates
- No traversal needed because hash map stores node references

---

## üîÑ Variations

| Variation | Difference | Problem |
|-----------|------------|---------|
| LFU Cache | Evict least frequently used | LC 460 |
| TTL Cache | Evict based on time | Custom |
| Bounded Cache | Different eviction policies | Custom |
| Thread-safe | Add synchronization | Custom |

---

## ‚ö†Ô∏è Common Mistakes

### 1. Forgetting to Store Key in Node

```python
# ‚ùå WRONG: Node without key
class ListNode:
    def __init__(self, val):
        self.val = val  # No key!

# When evicting, how do we know which key to remove from hash map?

# ‚úÖ CORRECT: Store key in node
class ListNode:
    def __init__(self, key, val):
        self.key = key  # Need this for eviction!
        self.val = val
```

### 2. Not Updating Both Data Structures

```python
# ‚ùå WRONG: Only updating hash map
def put(self, key, value):
    if key in self.cache:
        self.cache[key].val = value  # Updated value...
        # But didn't move to front of DLL!

# ‚úÖ CORRECT: Update both
def put(self, key, value):
    if key in self.cache:
        node = self.cache[key]
        node.val = value
        self._move_to_front(node)  # Also update DLL order!
```

### 3. Evicting Before Capacity Check

```python
# ‚ùå WRONG: Wrong order
def put(self, key, value):
    node = ListNode(key, value)
    self.cache[key] = node
    self._add_to_front(node)
    
    if len(self.cache) > self.capacity:
        # Might evict the just-added node!
        lru = self.tail.prev
        self._remove(lru)
        del self.cache[lru.key]

# ‚úÖ CORRECT: Evict first if needed
def put(self, key, value):
    if key not in self.cache:
        if len(self.cache) >= self.capacity:
            # Make room FIRST
            lru = self.tail.prev
            self._remove(lru)
            del self.cache[lru.key]
        
        # Then add new node
        node = ListNode(key, value)
        self.cache[key] = node
        self._add_to_front(node)
```

### 4. Not Using Dummy Head/Tail

```python
# ‚ùå HARDER: Without dummy nodes, many edge cases
def _add_to_front(self, node):
    if not self.head:
        self.head = self.tail = node
    else:
        node.next = self.head
        self.head.prev = node
        self.head = node
    # ... and similar complexity for other operations

# ‚úÖ EASIER: Dummy nodes eliminate edge cases
def _add_to_front(self, node):
    node.prev = self.head
    node.next = self.head.next
    self.head.next.prev = node
    self.head.next = node
    # Works even when list is "empty" (just dummy nodes)
```

---

## üìù Practice Problems (Progressive)

| Problem | Difficulty | Key Focus |
|---------|------------|-----------|
| Design HashMap | üü¢ Easy | Hash basics |
| LRU Cache | üü° Medium | This problem |
| LFU Cache | üî¥ Hard | Frequency tracking |
| Insert Delete GetRandom | üü° Medium | Similar pattern |

**Related LeetCode:**
- [460. LFU Cache](https://leetcode.com/problems/lfu-cache/)
- [380. Insert Delete GetRandom O(1)](https://leetcode.com/problems/insert-delete-getrandom-o1/)
- [432. All O`one Data Structure](https://leetcode.com/problems/all-oone-data-structure/)

<details>
<summary><strong>üß† Spaced Repetition Schedule</strong></summary>

- **Day 1:** Understand the design, implement basic version
- **Day 3:** Implement from scratch without reference
- **Day 7:** Explain why both structures are needed
- **Day 14:** Solve LFU Cache
- **Day 30:** < 15 min clean implementation

</details>

---

## üé§ Interview Context

<details>
<summary><strong>Communication Template</strong></summary>

**1. Clarify (1 min):**
> "LRU eviction means removing the least recently accessed item when at capacity. Both get and put should be O(1)?"

**2. Design discussion (2 min):**
> "Hash map alone gives O(1) lookup but can't track order. Linked list alone gives O(1) reordering but O(n) lookup. I'll combine them: hash map maps keys to DLL nodes, DLL maintains access order."

**3. Key insight:**
> "Storing the key in each node is crucial - when evicting from the list, I need to know which key to remove from the hash map."

**4. Edge cases:**
> "I'll use dummy head/tail nodes to simplify edge cases when adding/removing."

</details>

**Company Frequency:**

| Company | Frequency | Notes |
|---------|-----------|-------|
| Amazon | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Extremely common |
| Meta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Top asked |
| Microsoft | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Classic |
| Google | ‚≠ê‚≠ê‚≠ê‚≠ê | May ask variations |
| Netflix | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Cache focus |

---

## ‚è±Ô∏è Time Estimates

| Activity | Time |
|----------|------|
| Clarify requirements | 1 min |
| Design discussion | 2-3 min |
| Implement | 12-15 min |
| Test edge cases | 3 min |
| **Total** | **18-22 min** |

---

> **üí° Key Insight:** Neither hash map nor doubly linked list alone provides O(1) for all operations. Combined: hash map gives O(1) node lookup, DLL gives O(1) reordering. Store the key in each node so you know what to delete from the hash map when evicting.

> **üîó Related:** [Design Overview](./8.1-Design-Overview.md) | [RandomizedSet](./8.5-RandomizedSet-LC380.md) | [Hash Map Operations](../02-Hash-Map-Set/2.1-Hash-Map-Operations.md)
