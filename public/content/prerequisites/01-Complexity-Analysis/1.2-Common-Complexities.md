# 1.2 Common Complexities

> **The 7 complexity classes you'll encounter 99% of the time.**
>
> â±ï¸ *Estimated reading: 25 minutes*

---

## ğŸ¯ The Complexity Hierarchy

From fastest to slowest, memorize these in order:

```
O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿) < O(n!)
 ğŸŸ¢      ğŸŸ¢        ğŸŸ¡        ğŸŸ¡          ğŸ”´      ğŸ”´       ğŸ”´
fast    fast    moderate  moderate    slow   very slow  unusable
```

### Visual Growth Comparison

For n = 1,000 elements:

```
O(1)       â†’                1
O(log n)   â†’               10
O(n)       â†’            1,000
O(n log n) â†’           10,000
O(nÂ²)      â†’        1,000,000
O(2â¿)      â†’ â†’ â†’ â†’ â†’ â†’ â†’ â†’ â†’ (number with 301 digits!)
O(n!)      â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’ (number with 2,568 digits!)
```

---

## ğŸŸ¢ O(1) â€” Constant Time

### What It Means

The algorithm takes the same amount of time **regardless of input size**.

| Input Size | Operations |
|------------|------------|
| 10 | 1 |
| 1,000 | 1 |
| 1,000,000 | 1 |

### Real-World Analogy

**Looking at your watch.** Whether you want to know the time after 1 second or 1 year, glancing at your watch takes the same amount of time.

### Code Examples

```python
def get_first_element(arr):
    """Access array element by index - O(1)"""
    return arr[0]

def hash_lookup(dictionary, key):
    """Dictionary/HashMap lookup - O(1) average"""
    return dictionary.get(key)

def check_even(n):
    """Simple arithmetic - O(1)"""
    return n % 2 == 0

def push_to_stack(stack, value):
    """Push to end of list - O(1)"""
    stack.append(value)

def get_array_length(arr):
    """Get length (stored as metadata) - O(1)"""
    return len(arr)
```

```javascript
// JavaScript equivalents
function getFirstElement(arr) {
    return arr[0];
}

function mapLookup(map, key) {
    return map.get(key);
}

function checkEven(n) {
    return n % 2 === 0;
}
```

### Common O(1) Operations

| Data Structure | Operation | Python | JavaScript |
|----------------|-----------|--------|------------|
| Array | Access by index | `arr[i]` | `arr[i]` |
| Array | Get length | `len(arr)` | `arr.length` |
| Array | Push to end | `arr.append(x)` | `arr.push(x)` |
| Array | Pop from end | `arr.pop()` | `arr.pop()` |
| HashMap | Get/Set | `dict[key]` | `map.get(key)` |
| Set | Check membership | `x in set` | `set.has(x)` |
| Stack | Push/Pop | `stack.append/pop()` | `push()/pop()` |

### âš ï¸ Gotcha: Amortized O(1)

Some operations are O(1) **on average** but occasionally O(n):

```python
# Python list.append() is O(1) amortized
# Occasionally, Python needs to resize the array: O(n)
# But spread over many operations, it averages to O(1)

arr = []
for i in range(1000000):
    arr.append(i)  # Each append is O(1) amortized
```

---

## ğŸŸ¢ O(log n) â€” Logarithmic Time

### What It Means

The algorithm **cuts the problem in half** with each step.

| Input Size | Operations (logâ‚‚) |
|------------|-------------------|
| 16 | 4 |
| 1,024 | 10 |
| 1,000,000 | 20 |
| 1,000,000,000 | 30 |

**A billion elements requires only 30 steps!**

### Real-World Analogy

**Guessing a number between 1 and 100.** You ask: "Is it greater than 50?" Each question eliminates half the possibilities.

```
1-100: "Greater than 50?" â†’ Yes
51-100: "Greater than 75?" â†’ No
51-75: "Greater than 63?" â†’ Yes
64-75: "Greater than 69?" â†’ No
64-69: "Greater than 66?" â†’ Yes
67-69: "Greater than 68?" â†’ No
67-68: "Is it 68?" â†’ Yes!

7 questions to find any number from 1-100!
```

### Code Examples

```python
def binary_search(arr, target):
    """Classic binary search - O(log n)"""
    left, right = 0, len(arr) - 1
    
    while left <= right:
        mid = (left + right) // 2
        
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1   # Discard left half
        else:
            right = mid - 1  # Discard right half
    
    return -1

def count_digits(n):
    """Count digits in a number - O(log n)"""
    if n == 0:
        return 1
    count = 0
    while n > 0:
        n //= 10  # Divide by 10 each time
        count += 1
    return count
```

```javascript
function binarySearch(arr, target) {
    let left = 0, right = arr.length - 1;
    
    while (left <= right) {
        const mid = Math.floor((left + right) / 2);
        if (arr[mid] === target) return mid;
        if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}
```

### Common O(log n) Operations

| Operation | When It's O(log n) |
|-----------|-------------------|
| Binary Search | On sorted array |
| Balanced BST operations | Insert, Delete, Search |
| Heap operations | Insert, Extract |
| Exponentiation by squaring | `pow(x, n)` optimized |
| Finding GCD | Euclidean algorithm |

### Why Is It Called "Logarithmic"?

If you halve n until you reach 1:
- n â†’ n/2 â†’ n/4 â†’ n/8 â†’ ... â†’ 1
- Number of steps: logâ‚‚(n)

```
n = 8:  8 â†’ 4 â†’ 2 â†’ 1  (3 steps = logâ‚‚(8))
n = 16: 16 â†’ 8 â†’ 4 â†’ 2 â†’ 1  (4 steps = logâ‚‚(16))
```

---

## ğŸŸ¡ O(n) â€” Linear Time

### What It Means

Time grows **proportionally** with input size. Double the input = double the time.

| Input Size | Operations |
|------------|------------|
| 100 | 100 |
| 1,000 | 1,000 |
| 1,000,000 | 1,000,000 |

### Real-World Analogy

**Reading a book.** A 200-page book takes twice as long to read as a 100-page book.

### Code Examples

```python
def find_maximum(arr):
    """Find max element - O(n)"""
    max_val = arr[0]
    for element in arr:    # Visit each element once
        if element > max_val:
            max_val = element
    return max_val

def sum_array(arr):
    """Sum all elements - O(n)"""
    total = 0
    for num in arr:
        total += num
    return total

def linear_search(arr, target):
    """Find element in unsorted array - O(n)"""
    for i, element in enumerate(arr):
        if element == target:
            return i
    return -1

def count_occurrences(arr, target):
    """Count how many times target appears - O(n)"""
    count = 0
    for element in arr:
        if element == target:
            count += 1
    return count
```

```javascript
function findMaximum(arr) {
    let maxVal = arr[0];
    for (const element of arr) {
        if (element > maxVal) {
            maxVal = element;
        }
    }
    return maxVal;
}

function sumArray(arr) {
    return arr.reduce((sum, num) => sum + num, 0);
}
```

### Common O(n) Operations

| Operation | Example |
|-----------|---------|
| Traversing array | `for x in arr` |
| Linear search | Find element in unsorted array |
| Counting elements | Count matching items |
| Copying array | `arr.copy()` or `[...arr]` |
| Finding min/max | Without sorting |
| Two pointers (meeting) | Start from ends, meet in middle |

### Multiple Passes Are Still O(n)

```python
def three_pass(arr):
    """Three separate loops - still O(n)"""
    total = 0
    for x in arr:        # O(n)
        total += x
    
    for x in arr:        # O(n)
        print(x)
    
    for x in arr:        # O(n)
        print(x * 2)
    
    # Total: O(n) + O(n) + O(n) = O(3n) = O(n)
```

---

## ğŸŸ¡ O(n log n) â€” Linearithmic Time

### What It Means

Slightly worse than linear, but much better than quadratic. This is the **optimal complexity for comparison-based sorting**.

| Input Size | Operations (n Ã— logâ‚‚n) |
|------------|----------------------|
| 100 | ~700 |
| 1,000 | ~10,000 |
| 1,000,000 | ~20,000,000 |

### Real-World Analogy

**Organizing a library.** You go through each book (n) and for each, you need to find its correct alphabetical position (log n comparisons using binary search).

### Code Examples

```python
def merge_sort(arr):
    """Merge sort - O(n log n)"""
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])    # log n levels
    right = merge_sort(arr[mid:])   # log n levels
    
    return merge(left, right)       # O(n) at each level

def merge(left, right):
    """Merge two sorted arrays - O(n)"""
    result = []
    i = j = 0
    
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    result.extend(left[i:])
    result.extend(right[j:])
    return result
```

```javascript
function mergeSort(arr) {
    if (arr.length <= 1) return arr;
    
    const mid = Math.floor(arr.length / 2);
    const left = mergeSort(arr.slice(0, mid));
    const right = mergeSort(arr.slice(mid));
    
    return merge(left, right);
}

function merge(left, right) {
    const result = [];
    let i = 0, j = 0;
    
    while (i < left.length && j < right.length) {
        if (left[i] <= right[j]) {
            result.push(left[i++]);
        } else {
            result.push(right[j++]);
        }
    }
    
    return result.concat(left.slice(i)).concat(right.slice(j));
}
```

### Why O(n log n)?

```
Merge Sort Visualization:

Level 0:    [5, 2, 8, 1, 9, 3, 7, 4]        â† n elements
             /                    \
Level 1: [5,2,8,1]           [9,3,7,4]      â† n/2 + n/2 = n work
           /    \               /    \
Level 2: [5,2] [8,1]       [9,3] [7,4]      â† n/4 Ã— 4 = n work
          / \   / \         / \   / \
Level 3: [5][2][8][1]     [9][3][7][4]      â† n/8 Ã— 8 = n work

Total levels: logâ‚‚(n) = 3
Work per level: O(n)
Total: O(n) Ã— O(log n) = O(n log n)
```

### Common O(n log n) Algorithms

| Algorithm | Notes |
|-----------|-------|
| Merge Sort | Always O(n log n) |
| Quick Sort | Average O(n log n), worst O(nÂ²) |
| Heap Sort | Always O(n log n) |
| Tim Sort | Python's `sort()`, JavaScript's `sort()` |
| Building a BST | Inserting n elements |

---

## ğŸ”´ O(nÂ²) â€” Quadratic Time

### What It Means

Time grows with the **square** of input size. 10x input = 100x time.

| Input Size | Operations |
|------------|------------|
| 10 | 100 |
| 100 | 10,000 |
| 1,000 | 1,000,000 |
| 10,000 | 100,000,000 |

### Real-World Analogy

**Everyone shaking hands at a party.** With n people, there are n Ã— (n-1) / 2 â‰ˆ nÂ² handshakes.

```
3 people: A-B, A-C, B-C = 3 handshakes
4 people: A-B, A-C, A-D, B-C, B-D, C-D = 6 handshakes
10 people: 45 handshakes
100 people: 4,950 handshakes
```

### Code Examples

```python
def bubble_sort(arr):
    """Bubble sort - O(nÂ²)"""
    n = len(arr)
    for i in range(n):              # n iterations
        for j in range(n - i - 1):  # n iterations (roughly)
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
    return arr

def has_duplicate_naive(arr):
    """Check for duplicates - O(nÂ²)"""
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j]:
                return True
    return False

def print_all_pairs(arr):
    """Print all pairs - O(nÂ²)"""
    for i in range(len(arr)):
        for j in range(len(arr)):
            print(arr[i], arr[j])
```

```javascript
function bubbleSort(arr) {
    const n = arr.length;
    for (let i = 0; i < n; i++) {
        for (let j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];
            }
        }
    }
    return arr;
}
```

### When O(nÂ²) Is Acceptable

| Input Size | O(nÂ²) Operations | Acceptable? |
|------------|------------------|-------------|
| n â‰¤ 100 | 10,000 | âœ… Yes |
| n â‰¤ 1,000 | 1,000,000 | âš ï¸ Maybe |
| n â‰¤ 10,000 | 100,000,000 | âŒ Too slow |
| n â‰¥ 100,000 | 10,000,000,000+ | âŒ Unusable |

**Rule of thumb:** Most computers handle ~10â¸ operations per second. For interview problems with n â‰¤ 10â´, O(nÂ²) might pass.

### Optimizing O(nÂ²) to O(n)

```python
# O(nÂ²) - Check all pairs for duplicate
def has_duplicate_slow(arr):
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j]:
                return True
    return False

# O(n) - Use a set
def has_duplicate_fast(arr):
    seen = set()
    for x in arr:
        if x in seen:
            return True
        seen.add(x)
    return False
```

---

## ğŸ”´ O(2â¿) â€” Exponential Time

### What It Means

Time **doubles** with each additional element. Grows astronomically fast.

| Input Size | Operations |
|------------|------------|
| 10 | 1,024 |
| 20 | 1,048,576 |
| 30 | 1,073,741,824 |
| 40 | 1,099,511,627,776 |

### Real-World Analogy

**Deciding what to wear.** With n items of clothing, you have 2â¿ possible outfit combinations (each item is either worn or not).

### Code Examples

```python
def fibonacci_recursive(n):
    """Naive Fibonacci - O(2â¿)"""
    if n <= 1:
        return n
    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)

def generate_subsets(arr):
    """Generate all subsets - O(2â¿)"""
    if not arr:
        return [[]]
    
    first = arr[0]
    rest = arr[1:]
    
    subsets_without_first = generate_subsets(rest)
    subsets_with_first = [[first] + subset for subset in subsets_without_first]
    
    return subsets_without_first + subsets_with_first
```

```javascript
function fibonacciRecursive(n) {
    if (n <= 1) return n;
    return fibonacciRecursive(n - 1) + fibonacciRecursive(n - 2);
}
```

### Why Fibonacci is O(2â¿)

```
fib(5)
â”œâ”€â”€ fib(4)
â”‚   â”œâ”€â”€ fib(3)
â”‚   â”‚   â”œâ”€â”€ fib(2)
â”‚   â”‚   â”‚   â”œâ”€â”€ fib(1)
â”‚   â”‚   â”‚   â””â”€â”€ fib(0)
â”‚   â”‚   â””â”€â”€ fib(1)
â”‚   â””â”€â”€ fib(2)
â”‚       â”œâ”€â”€ fib(1)
â”‚       â””â”€â”€ fib(0)
â””â”€â”€ fib(3)
    â”œâ”€â”€ fib(2)
    â”‚   â”œâ”€â”€ fib(1)
    â”‚   â””â”€â”€ fib(0)
    â””â”€â”€ fib(1)

Each level roughly doubles the number of calls!
```

### When O(2â¿) Is Acceptable

Only when n is very small (typically n â‰¤ 20-25) or when you're generating all possible combinations and there's no better approach.

| Problem Type | Acceptable n |
|--------------|--------------|
| Subset generation | n â‰¤ 20 |
| Brute force password | Very short passwords only |
| Traveling Salesman (exact) | n â‰¤ 15-20 |

---

## ğŸ”´ O(n!) â€” Factorial Time

### What It Means

The **worst practical complexity**. Grows faster than exponential.

| Input Size | Operations |
|------------|------------|
| 5 | 120 |
| 10 | 3,628,800 |
| 12 | 479,001,600 |
| 15 | 1,307,674,368,000 |
| 20 | 2,432,902,008,176,640,000 |

### Real-World Analogy

**Arranging books on a shelf.** With n books, there are n! ways to arrange them:
- 3 books: 3! = 6 arrangements
- 10 books: 10! = 3,628,800 arrangements

### Code Examples

```python
def generate_permutations(arr):
    """Generate all permutations - O(n!)"""
    if len(arr) <= 1:
        return [arr]
    
    result = []
    for i, element in enumerate(arr):
        remaining = arr[:i] + arr[i+1:]
        for perm in generate_permutations(remaining):
            result.append([element] + perm)
    
    return result

def traveling_salesman_brute(distances):
    """Try all routes - O(n!)"""
    from itertools import permutations
    
    cities = range(len(distances))
    min_distance = float('inf')
    
    for perm in permutations(cities):  # n! permutations
        total = sum(distances[perm[i]][perm[i+1]] 
                    for i in range(len(perm) - 1))
        min_distance = min(min_distance, total)
    
    return min_distance
```

### When O(n!) Appears

- Generating all permutations
- Brute force for optimization problems (TSP)
- Checking all orderings

### Practical Limits

| n | n! | Time at 10â¹ ops/sec |
|---|-----|---------------------|
| 10 | 3.6M | 0.0036 seconds |
| 12 | 479M | 0.48 seconds |
| 15 | 1.3T | 22 minutes |
| 20 | 2.4Ã—10Â¹â¸ | 77 years |

**Rule:** If your algorithm is O(n!), it's only usable for n â‰¤ 10-12.

---

## ğŸ“Š Visual Comparison Chart

```
Operations
    â”‚
10Â¹Â²â”œ                                            â•± O(2â¿)
    â”‚                                         â•±
10Â¹â°â”œ                                      â•±
    â”‚                                   â•±         â•± O(nÂ²)
10â¸ â”œ                               â•±          â•±
    â”‚                           â•±           â•±
10â¶ â”œ                       â•±            â•±          â•± O(n log n)
    â”‚                   â•±             â•±          â•±
10â´ â”œ               â•±              â•±          â•±â”€â”€â”€â”€â”€â”€â”€ O(n)
    â”‚           â•±               â•±          â•±
10Â² â”œ       â•±                â•±          â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O(log n)
    â”‚   â•±                 â•±          â•±
  1 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O(1)
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–º n
        10     100    1,000  10,000 100,000
```

---

## ğŸ¯ Quick Decision Table

When solving a problem, use this table to check if your solution will be fast enough:

| If n â‰¤ | These complexities work | Example problems |
|--------|------------------------|------------------|
| 10 | O(n!), O(2â¿), O(nâ´) | Brute force anything |
| 20 | O(2â¿), O(nÂ³) | Subset generation |
| 100 | O(nÂ³) | Floyd-Warshall |
| 500 | O(nÂ³) | Small matrix operations |
| 5,000 | O(nÂ²) | Bubble sort (just barely) |
| 10â¶ | O(n log n) | Sorting large arrays |
| 10â¸ | O(n) | Single-pass algorithms |
| 10â¹+ | O(log n), O(1) | Binary search, hash lookup |

---

> **ğŸ’¡ Key Insight:** The difference between O(n) and O(nÂ²) isn't just "a bit slower"â€”at scale, it's the difference between 1 second and 3 hours. Understanding complexity classes helps you immediately know whether an approach is viable before writing a single line of code.

---

**Next:** [1.3 Analyzing Loops](./1.3-Analyzing-Loops.md) â†’
