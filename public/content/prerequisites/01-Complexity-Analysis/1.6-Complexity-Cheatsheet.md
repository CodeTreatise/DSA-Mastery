# 1.6 Complexity Cheatsheet

> **Your quick reference for all things Big O. Print this, bookmark it, review it.**
>
> â±ï¸ *Reference document â€” use as needed*

---

## ğŸ“Š Big O Growth Comparison

### At a Glance

| Complexity | Name | 10 | 100 | 1,000 | 10,000 | Verdict |
|------------|------|-----|------|-------|--------|---------|
| **O(1)** | Constant | 1 | 1 | 1 | 1 | âœ… Perfect |
| **O(log n)** | Logarithmic | 3 | 7 | 10 | 13 | âœ… Excellent |
| **O(n)** | Linear | 10 | 100 | 1,000 | 10,000 | âœ… Good |
| **O(n log n)** | Linearithmic | 33 | 664 | 9,966 | 132,877 | âœ… Good |
| **O(nÂ²)** | Quadratic | 100 | 10,000 | 1,000,000 | 100,000,000 | âš ï¸ Careful |
| **O(nÂ³)** | Cubic | 1,000 | 1,000,000 | 10â¹ | 10Â¹Â² | âŒ Avoid |
| **O(2â¿)** | Exponential | 1,024 | 10Â³â° | 10Â³â°Â¹ | âˆ | âŒ Avoid |
| **O(n!)** | Factorial | 3.6M | 10Â¹âµâ¸ | âˆ | âˆ | âŒ Avoid |

### Growth Hierarchy (Slowest to Fastest)

```
O(1) < O(log n) < O(âˆšn) < O(n) < O(n log n) < O(nÂ²) < O(nÂ³) < O(2â¿) < O(n!)
                   â”‚                            â”‚               â”‚
              Rarely seen               "Polynomial"      "Exponential"
                                         Acceptable      Usually not OK
```

---

## âš¡ Data Structure Operations

### Arrays

| Operation | Average | Worst | Notes |
|-----------|---------|-------|-------|
| Access by index | O(1) | O(1) | `arr[i]` |
| Search (unsorted) | O(n) | O(n) | Linear scan |
| Search (sorted) | O(log n) | O(log n) | Binary search |
| Insert at end | O(1)* | O(n) | *Amortized |
| Insert at beginning | O(n) | O(n) | Shift all elements |
| Insert at middle | O(n) | O(n) | Shift elements |
| Delete at end | O(1) | O(1) | |
| Delete at beginning | O(n) | O(n) | Shift all elements |
| Delete at middle | O(n) | O(n) | Shift elements |

### Linked Lists

| Operation | Singly | Doubly | Notes |
|-----------|--------|--------|-------|
| Access by index | O(n) | O(n) | Must traverse |
| Search | O(n) | O(n) | Must traverse |
| Insert at head | O(1) | O(1) | |
| Insert at tail | O(n)/O(1)* | O(1) | *With tail pointer |
| Insert at middle | O(n) | O(n) | Finding position |
| Delete at head | O(1) | O(1) | |
| Delete at tail | O(n) | O(1) | |
| Delete at middle | O(n) | O(n) | Finding position |

### Hash Tables (HashMap/Dictionary)

| Operation | Average | Worst | Notes |
|-----------|---------|-------|-------|
| Insert | O(1) | O(n) | Collision chains |
| Delete | O(1) | O(n) | |
| Search | O(1) | O(n) | |
| Space | O(n) | O(n) | |

### Sets (HashSet)

| Operation | Average | Worst |
|-----------|---------|-------|
| Add | O(1) | O(n) |
| Remove | O(1) | O(n) |
| Contains | O(1) | O(n) |

### Stacks & Queues

| Operation | Stack | Queue | Notes |
|-----------|-------|-------|-------|
| Push/Enqueue | O(1) | O(1) | |
| Pop/Dequeue | O(1) | O(1) | |
| Peek | O(1) | O(1) | |
| Search | O(n) | O(n) | Must traverse |

### Binary Search Tree (BST)

| Operation | Average | Worst | Notes |
|-----------|---------|-------|-------|
| Search | O(log n) | O(n) | Worst = unbalanced |
| Insert | O(log n) | O(n) | |
| Delete | O(log n) | O(n) | |
| Min/Max | O(log n) | O(n) | |

### Balanced BST (AVL, Red-Black)

| Operation | Average | Worst | Notes |
|-----------|---------|-------|-------|
| Search | O(log n) | O(log n) | Guaranteed |
| Insert | O(log n) | O(log n) | |
| Delete | O(log n) | O(log n) | |

### Heaps (Priority Queue)

| Operation | Time | Notes |
|-----------|------|-------|
| Insert | O(log n) | Bubble up |
| Extract Min/Max | O(log n) | Bubble down |
| Peek | O(1) | |
| Build heap | O(n) | Heapify |
| Search | O(n) | Not designed for this |

### Graphs

| Representation | Space | Add Edge | Check Edge | Find Neighbors |
|----------------|-------|----------|------------|----------------|
| Adjacency List | O(V + E) | O(1) | O(degree) | O(degree) |
| Adjacency Matrix | O(VÂ²) | O(1) | O(1) | O(V) |

---

## ğŸ”„ Sorting Algorithms

| Algorithm | Best | Average | Worst | Space | Stable? |
|-----------|------|---------|-------|-------|---------|
| **Bubble Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | âœ… |
| **Selection Sort** | O(nÂ²) | O(nÂ²) | O(nÂ²) | O(1) | âŒ |
| **Insertion Sort** | O(n) | O(nÂ²) | O(nÂ²) | O(1) | âœ… |
| **Merge Sort** | O(n log n) | O(n log n) | O(n log n) | O(n) | âœ… |
| **Quick Sort** | O(n log n) | O(n log n) | O(nÂ²) | O(log n) | âŒ |
| **Heap Sort** | O(n log n) | O(n log n) | O(n log n) | O(1) | âŒ |
| **Counting Sort** | O(n + k) | O(n + k) | O(n + k) | O(k) | âœ… |
| **Radix Sort** | O(nk) | O(nk) | O(nk) | O(n + k) | âœ… |
| **Bucket Sort** | O(n + k) | O(n + k) | O(nÂ²) | O(n) | âœ… |
| **Tim Sort** | O(n) | O(n log n) | O(n log n) | O(n) | âœ… |

**Notes:**
- k = range of values (Counting Sort) or number of digits (Radix Sort)
- Tim Sort is used by Python and JavaScript
- Quick Sort is often fastest in practice despite O(nÂ²) worst case

---

## ğŸ” Search Algorithms

| Algorithm | Time | Space | Requirement |
|-----------|------|-------|-------------|
| Linear Search | O(n) | O(1) | None |
| Binary Search | O(log n) | O(1) | Sorted |
| Jump Search | O(âˆšn) | O(1) | Sorted |
| Interpolation Search | O(log log n)* | O(1) | Sorted, uniform |
| Hash Lookup | O(1) avg | O(n) | Hash table |

*Best case for uniformly distributed data

---

## ğŸŒ³ Tree & Graph Algorithms

### Tree Traversals

| Algorithm | Time | Space |
|-----------|------|-------|
| DFS (Preorder/Inorder/Postorder) | O(n) | O(h) |
| BFS (Level Order) | O(n) | O(w) |

Where: n = nodes, h = height, w = max width

### Graph Algorithms

| Algorithm | Time | Space | Use Case |
|-----------|------|-------|----------|
| **BFS** | O(V + E) | O(V) | Shortest path (unweighted) |
| **DFS** | O(V + E) | O(V) | Connectivity, cycles |
| **Dijkstra** | O((V + E) log V) | O(V) | Shortest path (weighted) |
| **Bellman-Ford** | O(VE) | O(V) | Negative weights |
| **Floyd-Warshall** | O(VÂ³) | O(VÂ²) | All pairs shortest |
| **Topological Sort** | O(V + E) | O(V) | DAG ordering |
| **Kruskal (MST)** | O(E log E) | O(V) | Minimum spanning tree |
| **Prim (MST)** | O(E log V) | O(V) | Minimum spanning tree |
| **Union-Find** | O(Î±(n)) â‰ˆ O(1) | O(n) | Disjoint sets |

---

## ğŸ“ Common Patterns

### Loop Patterns â†’ Complexity

| Pattern | Complexity | Example |
|---------|------------|---------|
| Single loop | O(n) | `for i in range(n)` |
| Two sequential loops | O(n) | `for x in a; for x in a` |
| Nested loops | O(nÂ²) | `for i in n: for j in n` |
| Nested with different arrays | O(n Ã— m) | `for x in a: for y in b` |
| Loop halving | O(log n) | `while n > 0: n //= 2` |
| Outer + halving inner | O(n log n) | `for i in n: while j //= 2` |
| Three nested loops | O(nÂ³) | `for i: for j: for k` |

### Recursion Patterns â†’ Complexity

| Pattern | Recurrence | Result |
|---------|------------|--------|
| Linear recursion | T(n) = T(n-1) + O(1) | O(n) |
| Linear + linear work | T(n) = T(n-1) + O(n) | O(nÂ²) |
| Binary (one branch) | T(n) = T(n/2) + O(1) | O(log n) |
| Binary (one branch + work) | T(n) = T(n/2) + O(n) | O(n) |
| Binary (two branches) | T(n) = 2T(n/2) + O(1) | O(n) |
| Binary (two branches + work) | T(n) = 2T(n/2) + O(n) | O(n log n) |
| Exponential branching | T(n) = 2T(n-1) + O(1) | O(2â¿) |

---

## ğŸ“Š Input Size â†’ Expected Complexity

Use this table to estimate the expected time complexity based on problem constraints:

| Input Size (n) | Max Acceptable | Common Algorithms |
|----------------|----------------|-------------------|
| n â‰¤ 10 | O(n!), O(2â¿) | Brute force, permutations |
| n â‰¤ 20 | O(2â¿) | Subset generation, bitmask DP |
| n â‰¤ 100 | O(nÂ³) | Floyd-Warshall |
| n â‰¤ 500 | O(nÂ³) | Matrix operations |
| n â‰¤ 5,000 | O(nÂ²) | Simple DP, bubble sort |
| n â‰¤ 10âµ | O(n log n) | Sorting, balanced BST |
| n â‰¤ 10â¶ | O(n) | Linear scan, two pointers |
| n â‰¤ 10â¸ | O(n) | Linear scan (tight) |
| n â‰¤ 10â¹ | O(log n), O(1) | Binary search, math |
| n > 10â¹ | O(log n), O(1) | Math formulas only |

---

## ğŸ§® Mathematical Formulas

### Summation Formulas

| Sum | Result | Big O |
|-----|--------|-------|
| 1 + 2 + 3 + ... + n | n(n+1)/2 | O(nÂ²) |
| 1 + 2 + 4 + ... + 2^k | 2^(k+1) - 1 | O(2^k) |
| 1 + 1/2 + 1/4 + ... | 2 | O(1) |
| n + n/2 + n/4 + ... | 2n | O(n) |

### Logarithm Properties

```
log(ab) = log(a) + log(b)
log(a/b) = log(a) - log(b)
log(a^n) = n Ã— log(a)
log_b(x) = log_c(x) / log_c(b)    â† All log bases are O(log n)
```

---

## ğŸ’» Language-Specific Operations

### Python

| Operation | Time | Notes |
|-----------|------|-------|
| `list.append(x)` | O(1)* | *Amortized |
| `list.pop()` | O(1) | From end |
| `list.pop(0)` | O(n) | From beginning |
| `list.insert(0, x)` | O(n) | At beginning |
| `list[i]` | O(1) | Index access |
| `x in list` | O(n) | Linear search |
| `x in set` | O(1) | Hash lookup |
| `dict[key]` | O(1) | Hash lookup |
| `list.sort()` | O(n log n) | Tim Sort, in-place |
| `sorted(list)` | O(n log n) | Creates new list |
| `list + list` | O(n) | Creates new list |
| `"".join(list)` | O(n) | Efficient string concat |
| `str += str` | O(n) | Creates new string each time |
| `collections.deque.appendleft()` | O(1) | Use for queue |
| `heapq.heappush()` | O(log n) | Min heap |
| `heapq.heappop()` | O(log n) | Min heap |

### JavaScript

| Operation | Time | Notes |
|-----------|------|-------|
| `array.push(x)` | O(1)* | *Amortized |
| `array.pop()` | O(1) | From end |
| `array.shift()` | O(n) | From beginning |
| `array.unshift(x)` | O(n) | At beginning |
| `array[i]` | O(1) | Index access |
| `array.includes(x)` | O(n) | Linear search |
| `set.has(x)` | O(1) | Hash lookup |
| `map.get(key)` | O(1) | Hash lookup |
| `array.sort()` | O(n log n) | Tim Sort |
| `array.concat(array)` | O(n) | Creates new array |
| `string + string` | O(n) | Creates new string |
| `array.join("")` | O(n) | Efficient string concat |

---

## ğŸ¤ Interview Quick Reference

### Communicating Complexity

**For Time:**
> "The time complexity is O(n) because we visit each element exactly once."

**For Space:**
> "The space complexity is O(n) because our hash map stores up to n elements."

**For Trade-offs:**
> "We're trading O(n) space for O(1) lookup time using a hash map."

### Red Flags in Your Analysis

- âŒ "It's O(n) because there's one loop" (check what's inside!)
- âŒ "It's O(nÂ²) because there are two loops" (are they nested or sequential?)
- âŒ "It's O(1) space" (did you forget the recursion stack?)

### Green Flags

- âœ… Explain WHY the complexity is what it is
- âœ… Consider both time AND space
- âœ… Mention trade-offs when relevant
- âœ… Identify the bottleneck operation

---

## ğŸ“ Printable One-Page Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIG O CHEATSHEET                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ COMPLEXITY RANKING (fastest â†’ slowest):                        â”‚
â”‚ O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿) < O(n!)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RULES:                                                          â”‚
â”‚ â€¢ Drop constants: O(2n) â†’ O(n)                                  â”‚
â”‚ â€¢ Drop lower terms: O(nÂ² + n) â†’ O(nÂ²)                          â”‚
â”‚ â€¢ Sequential = add, Nested = multiply                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ COMMON OPERATIONS:                                              â”‚
â”‚ â€¢ Array index:    O(1)    â€¢ Hash lookup:     O(1)               â”‚
â”‚ â€¢ Binary search:  O(log n)â€¢ Linear search:   O(n)               â”‚
â”‚ â€¢ Sorting:        O(n log n)â€¢ Nested loops:  O(nÂ²)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT SIZE â†’ TARGET COMPLEXITY:                                 â”‚
â”‚ n â‰¤ 20: O(2â¿) OK   n â‰¤ 5000: O(nÂ²) OK   n â‰¤ 10â¶: O(n log n)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MASTER THEOREM: T(n) = aT(n/b) + O(n^d)                        â”‚
â”‚ â€¢ a < b^d â†’ O(n^d)    â€¢ a = b^d â†’ O(n^d log n)                 â”‚
â”‚ â€¢ a > b^d â†’ O(n^(log_b a))                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

> **ğŸ’¡ Key Insight:** This cheatsheet is your quick reference, but understanding WHY these complexities occur is what impresses interviewers. Know the formulas, but also know the intuition.

---

**Next:** [1.7 Practice Problems](./1.7-Practice-Problems.md) â†’
