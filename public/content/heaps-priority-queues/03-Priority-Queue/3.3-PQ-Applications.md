# 3.3 Priority Queue Applications

## Definition

This section covers **real-world applications** of priority queues, demonstrating where this data structure provides optimal solutions across different domains.

```
Priority Queue Application Areas:

1. Algorithm Design
   ‚îú‚îÄ‚îÄ Dijkstra's Shortest Path
   ‚îú‚îÄ‚îÄ Prim's Minimum Spanning Tree
   ‚îú‚îÄ‚îÄ A* Search Algorithm
   ‚îî‚îÄ‚îÄ Huffman Coding

2. System Design
   ‚îú‚îÄ‚îÄ Task Scheduling
   ‚îú‚îÄ‚îÄ Load Balancing
   ‚îú‚îÄ‚îÄ Event-Driven Simulation
   ‚îî‚îÄ‚îÄ Rate Limiting

3. Interview Patterns
   ‚îú‚îÄ‚îÄ Top K Elements
   ‚îú‚îÄ‚îÄ Stream Processing
   ‚îú‚îÄ‚îÄ Merge Operations
   ‚îî‚îÄ‚îÄ Sliding Window
```

---

## üéØ Pattern Recognition

<details>
<summary><strong>Application Categories</strong></summary>

**Graph Algorithms:**
- Need next minimum/maximum node
- Greedy selection from candidates

**Scheduling:**
- Process tasks by priority/deadline
- Balance workload across resources

**Stream Processing:**
- Maintain running statistics
- Track K best/worst elements

**Merge Operations:**
- Combine sorted sequences
- Select minimum across multiple sources

</details>

---

## ‚úÖ Application Areas

| Domain | Application | Why PQ? |
|--------|-------------|---------|
| Graphs | Dijkstra, Prim | Get minimum edge/distance |
| OS | Process scheduling | Priority-based execution |
| Networks | Packet routing | QoS handling |
| Databases | External sorting | Merge sorted runs |
| AI/Gaming | A* pathfinding | Best-first search |
| Streaming | Top K, median | Maintain running state |

---

## üîó Concept Map

<details>
<summary><strong>Prerequisites & Next Steps</strong></summary>

**Before this, you should know:**
- [Priority Queue Basics](./3.1-PQ-Basics.md)
- [Priority Queue Implementation](./3.2-PQ-Implementation.md)

**After mastering this:**
- [Top K Pattern](../04-Top-K-Pattern/4.1-Top-K-Overview.md)
- [Two Heaps Pattern](../05-Two-Heaps-Pattern/5.1-Two-Heaps-Overview.md)
- [K-Way Merge Pattern](../06-K-Way-Merge-Pattern/6.1-K-Way-Merge-Overview.md)

**Related topics:**
- Graph Algorithms (Dijkstra, Prim)
- Greedy Algorithms
- Streaming Algorithms

</details>

---

## üìê How It Works

### Application 1: Dijkstra's Shortest Path

```
Why PQ for Dijkstra?

Without PQ (using array):
  Each step: O(V) to find minimum distance node
  Total: O(V¬≤)

With PQ:
  Each step: O(log V) to extract minimum
  Total: O((V + E) log V)

For sparse graphs (E << V¬≤), PQ is much faster!

Algorithm:
1. Put source node in PQ with distance 0
2. While PQ not empty:
   a. Extract node with minimum distance
   b. For each neighbor:
      - Calculate new distance
      - If shorter, add to PQ
3. Return distances array
```

### Application 2: Task Scheduling

```
OS Process Scheduling:

Processes with priorities:
  P1: priority 3, burst 10ms
  P2: priority 1, burst 5ms
  P3: priority 2, burst 8ms

Max-Priority Queue execution order:
  P1 (priority 3) ‚Üí P3 (priority 2) ‚Üí P2 (priority 1)

Why PQ?
- O(log n) to get next highest priority
- O(log n) to insert new process
- Dynamic: processes arrive/complete at runtime
```

### Application 3: Top K Elements

```
Find K largest from stream:

Stream: [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]
K = 3

Use Min-Heap of size K:
  - Keep K largest seen so far
  - Heap root = smallest of K largest
  - New element > root? Replace!

After processing: heap = [5, 5, 9]
Top 3 largest: 5, 5, 9
```

### Application 4: Event-Driven Simulation

```
Simulation Events:

PQ entries: (timestamp, event_type, data)
  (10, "arrival", customer_1)
  (15, "departure", customer_0)
  (22, "arrival", customer_2)

Process in order:
  1. Extract earliest event
  2. Process it (may generate new events)
  3. Insert new events
  4. Repeat

Why PQ?
- Always get next chronological event
- New events insert in O(log n)
- No need to re-sort
```

---

## üíª Code Implementation

### Application 1: Dijkstra's Algorithm

**Python:**
```python
import heapq
from collections import defaultdict

def dijkstra(graph: dict, start: str) -> dict:
    """
    Find shortest paths from start to all nodes.
    
    Args:
        graph: adjacency list {node: [(neighbor, weight), ...]}
        start: starting node
    
    Returns:
        distances: {node: shortest_distance}
    
    Time: O((V + E) log V)
    Space: O(V)
    """
    # Initialize distances
    distances = {node: float('inf') for node in graph}
    distances[start] = 0
    
    # Priority queue: (distance, node)
    pq = [(0, start)]
    
    while pq:
        curr_dist, curr_node = heapq.heappop(pq)
        
        # Skip if we've found a better path already
        if curr_dist > distances[curr_node]:
            continue
        
        # Explore neighbors
        for neighbor, weight in graph[curr_node]:
            new_dist = curr_dist + weight
            
            if new_dist < distances[neighbor]:
                distances[neighbor] = new_dist
                heapq.heappush(pq, (new_dist, neighbor))
    
    return distances


# Example usage
graph = {
    'A': [('B', 1), ('C', 4)],
    'B': [('A', 1), ('C', 2), ('D', 5)],
    'C': [('A', 4), ('B', 2), ('D', 1)],
    'D': [('B', 5), ('C', 1)]
}

distances = dijkstra(graph, 'A')
print(distances)  # {'A': 0, 'B': 1, 'C': 3, 'D': 4}
```

**JavaScript:**
```javascript
function dijkstra(graph, start) {
    const distances = {};
    for (const node in graph) {
        distances[node] = Infinity;
    }
    distances[start] = 0;
    
    // Simple priority queue using array (for demo)
    const pq = [[0, start]];  // [distance, node]
    
    while (pq.length > 0) {
        // Find minimum (in production, use proper heap)
        pq.sort((a, b) => a[0] - b[0]);
        const [currDist, currNode] = pq.shift();
        
        if (currDist > distances[currNode]) continue;
        
        for (const [neighbor, weight] of graph[currNode]) {
            const newDist = currDist + weight;
            if (newDist < distances[neighbor]) {
                distances[neighbor] = newDist;
                pq.push([newDist, neighbor]);
            }
        }
    }
    
    return distances;
}
```

### Application 2: Task Scheduler

**Python:**
```python
import heapq
from collections import Counter

def task_scheduler(tasks: list[str], n: int) -> int:
    """
    LC 621: Task Scheduler
    
    Find minimum time to complete all tasks with cooling period.
    
    Strategy:
    - Use max-heap to always run most frequent task
    - Track cooling tasks separately
    
    Time: O(tasks * n)
    Space: O(26) = O(1)
    """
    # Count task frequencies
    counts = Counter(tasks)
    
    # Max-heap of frequencies (negate for max behavior)
    max_heap = [-cnt for cnt in counts.values()]
    heapq.heapify(max_heap)
    
    time = 0
    
    while max_heap:
        cycle = []  # Tasks to run in this cycle
        
        # Run up to n+1 tasks in one cycle
        for _ in range(n + 1):
            if max_heap:
                cycle.append(heapq.heappop(max_heap))
        
        # Decrement counts, add back if not done
        for cnt in cycle:
            if cnt + 1 < 0:  # Still has remaining executions
                heapq.heappush(max_heap, cnt + 1)
        
        # Time for this cycle
        if max_heap:
            time += n + 1  # Full cycle
        else:
            time += len(cycle)  # Partial cycle (last one)
    
    return time


# Example
tasks = ["A", "A", "A", "B", "B", "B"]
n = 2
print(task_scheduler(tasks, n))  # 8: A‚ÜíB‚Üíidle‚ÜíA‚ÜíB‚Üíidle‚ÜíA‚ÜíB
```

### Application 3: Merge K Sorted Lists

**Python:**
```python
import heapq
from typing import Optional

class ListNode:
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next

def merge_k_lists(lists: list[Optional[ListNode]]) -> Optional[ListNode]:
    """
    LC 23: Merge K Sorted Lists
    
    Use min-heap to always get smallest element across all lists.
    
    Time: O(N log K) where N = total elements, K = number of lists
    Space: O(K) for the heap
    """
    # Heap entries: (value, list_index, node)
    # list_index for tie-breaking (nodes aren't comparable)
    heap = []
    
    for i, head in enumerate(lists):
        if head:
            heapq.heappush(heap, (head.val, i, head))
    
    dummy = ListNode()
    current = dummy
    
    while heap:
        val, i, node = heapq.heappop(heap)
        
        current.next = node
        current = current.next
        
        if node.next:
            heapq.heappush(heap, (node.next.val, i, node.next))
    
    return dummy.next
```

### Application 4: Event-Driven Simulation

**Python:**
```python
import heapq
from dataclasses import dataclass, field
from typing import Any

@dataclass(order=True)
class Event:
    time: float
    event_type: str = field(compare=False)
    data: Any = field(compare=False)


class EventSimulation:
    """
    Event-driven simulation using priority queue.
    Events are processed in chronological order.
    """
    
    def __init__(self):
        self._events = []
        self._current_time = 0
    
    def schedule(self, time: float, event_type: str, data: Any = None):
        """Schedule an event at given time."""
        event = Event(time, event_type, data)
        heapq.heappush(self._events, event)
    
    def next_event(self) -> Event:
        """Get and remove next event."""
        if not self._events:
            return None
        event = heapq.heappop(self._events)
        self._current_time = event.time
        return event
    
    @property
    def current_time(self):
        return self._current_time
    
    @property
    def has_events(self):
        return len(self._events) > 0


# Example: Customer queue simulation
sim = EventSimulation()

# Initial arrivals
sim.schedule(0, "arrival", {"customer_id": 1})
sim.schedule(5, "arrival", {"customer_id": 2})
sim.schedule(12, "arrival", {"customer_id": 3})

# Process events
while sim.has_events:
    event = sim.next_event()
    print(f"Time {event.time}: {event.event_type} - {event.data}")
    
    # Generate service completion event
    if event.event_type == "arrival":
        service_time = 8  # Fixed service time
        sim.schedule(
            event.time + service_time, 
            "departure", 
            event.data
        )
```

### Application 5: Running Median (Two Heaps)

**Python:**
```python
import heapq

class MedianFinder:
    """
    LC 295: Find Median from Data Stream
    
    Use two heaps:
    - max_heap: smaller half
    - min_heap: larger half
    
    Keep them balanced: |len(max) - len(min)| <= 1
    """
    
    def __init__(self):
        self.max_heap = []  # Negated for max behavior
        self.min_heap = []
    
    def addNum(self, num: int) -> None:
        # Always add to max_heap first
        heapq.heappush(self.max_heap, -num)
        
        # Move largest of max_heap to min_heap
        heapq.heappush(self.min_heap, -heapq.heappop(self.max_heap))
        
        # Balance: max_heap can have at most 1 more element
        if len(self.max_heap) < len(self.min_heap):
            heapq.heappush(self.max_heap, -heapq.heappop(self.min_heap))
    
    def findMedian(self) -> float:
        if len(self.max_heap) > len(self.min_heap):
            return -self.max_heap[0]
        return (-self.max_heap[0] + self.min_heap[0]) / 2


# Example
mf = MedianFinder()
mf.addNum(1)
print(mf.findMedian())  # 1.0
mf.addNum(2)
print(mf.findMedian())  # 1.5
mf.addNum(3)
print(mf.findMedian())  # 2.0
```

---

## ‚ö° Complexity Analysis

| Application | Time | Space | Notes |
|-------------|------|-------|-------|
| Dijkstra |" O((V+E) log V) "| O(V) | With binary heap |
| Task Scheduler |" O(n * cooling) "| O(1) | 26 letters max |
| Merge K Lists |" O(N log K) "| O(K) | N total, K lists |
| Running Median |" O(log n) per add "| O(n) | Two heaps |
| Top K |" O(n log K) "| O(K) | Fixed size heap |

---

## üîÑ Variations

| Application | Variation | Difference |
|-------------|-----------|------------|
| Dijkstra | Indexed PQ | Decrease-key support |
| Task Scheduler | Greedy math | No simulation |
| Merge K Lists | Divide & Conquer | Different approach |
| Running Median | Multiset | Allows deletion |

---

## ‚ö†Ô∏è Common Mistakes

### 1. Wrong Heap Type for Problem

```python
# ‚ùå Using min-heap when max-heap needed
# For Top K Largest, need min-heap (keep K largest, pop smallest)
# For Top K Smallest, need max-heap (keep K smallest, pop largest)

# ‚úÖ Think about what you're discarding
def top_k_largest(nums, k):
    # Min-heap: discard smallest, keep largest
    min_heap = []
    for num in nums:
        heapq.heappush(min_heap, num)
        if len(min_heap) > k:
            heapq.heappop(min_heap)  # Remove smallest
    return min_heap
```

### 2. Not Handling Duplicates in Dijkstra

```python
# ‚ùå Wrong: Processing same node multiple times at different distances
while pq:
    dist, node = heapq.heappop(pq)
    # Process node...

# ‚úÖ Correct: Skip if we've already found a shorter path
while pq:
    dist, node = heapq.heappop(pq)
    if dist > distances[node]:  # Already processed with shorter path
        continue
    # Process node...
```

### 3. Forgetting Tie-Breakers

```python
import heapq

# ‚ùå Wrong: Nodes aren't comparable
heap = []
heapq.heappush(heap, (5, node_a))
heapq.heappush(heap, (5, node_b))  # Error if same priority!

# ‚úÖ Correct: Add unique index
heap = []
heapq.heappush(heap, (5, 0, node_a))
heapq.heappush(heap, (5, 1, node_b))  # Index breaks tie
```

---

## üìù Practice Problems (Progressive)

### Easy (Basic applications)
- [ ] [Last Stone Weight (LC 1046)](https://leetcode.com/problems/last-stone-weight/)
- [ ] [Kth Largest Element in a Stream (LC 703)](https://leetcode.com/problems/kth-largest-element-in-a-stream/)

### Medium (Core applications)
- [ ] [Top K Frequent Elements (LC 347)](https://leetcode.com/problems/top-k-frequent-elements/)
- [ ] [Task Scheduler (LC 621)](https://leetcode.com/problems/task-scheduler/)
- [ ] [Merge K Sorted Lists (LC 23)](https://leetcode.com/problems/merge-k-sorted-lists/)
- [ ] [Network Delay Time (LC 743)](https://leetcode.com/problems/network-delay-time/) - Dijkstra

### Hard (Advanced applications)
- [ ] [Find Median from Data Stream (LC 295)](https://leetcode.com/problems/find-median-from-data-stream/)
- [ ] [Sliding Window Median (LC 480)](https://leetcode.com/problems/sliding-window-median/)
- [ ] [Trapping Rain Water II (LC 407)](https://leetcode.com/problems/trapping-rain-water-ii/)

<details>
<summary><strong>üß† Spaced Repetition Schedule</strong></summary>

- **Day 1:** Implement Dijkstra with PQ
- **Day 3:** Solve Task Scheduler
- **Day 7:** Merge K sorted lists
- **Day 14:** Running median
- **Day 30:** Combine multiple patterns

</details>

---

## üé§ Interview Context

<details>
<summary><strong>When to Suggest Priority Queue</strong></summary>

**Trigger phrases:**
- "Find K largest/smallest"
- "Process in order of priority"
- "Shortest path in weighted graph"
- "Merge sorted sequences"
- "Track median/middle element"
- "Schedule tasks by deadline"

**How to introduce:**
"I notice we need to repeatedly get the [minimum/maximum] element. This suggests using a Priority Queue, which I'll implement with a heap. This gives us O(log n) for each extraction instead of O(n) with a simple array."

**Follow-up questions to expect:**
- "Why not just sort?" ‚Üí Sorting is O(n log n) upfront; PQ is O(log n) per operation, better for streaming
- "What about BST?" ‚Üí PQ has O(1) peek vs O(log n), simpler implementation
- "Space complexity?" ‚Üí O(n) for heap, or O(K) if maintaining fixed size

</details>

**Company Focus:**

| Company | Focus Area | Example Problem |
|---------|------------|-----------------|
| Amazon | Scheduling | Task Scheduler |
| Google | Graph algorithms | Dijkstra, A* |
| Meta | Streaming | Median, Top K |
| Microsoft | System design | Event queues |

---

## ‚è±Ô∏è Time Estimates

| Application | Time to Implement | Notes |
|-------------|-------------------|-------|
| Dijkstra | 20-25 min | Standard pattern |
| Task Scheduler | 25-30 min | Greedy + heap |
| Merge K Lists | 15-20 min | Classic PQ |
| Running Median | 20-25 min | Two heaps |

---

## üí° Key Insight

> **Priority Queues shine when you need repeated access to extremes.** Whenever you hear "get minimum/maximum repeatedly," "process by priority," or "K best/worst," think Priority Queue. The O(log n) per operation beats O(n) scanning, especially for streaming data where sorting isn't possible.

---

## üîó Related

- **Previous:** [Priority Queue Implementation](./3.2-PQ-Implementation.md)
- **Patterns:** [Top K](../04-Top-K-Pattern/4.1-Top-K-Overview.md) | [Two Heaps](../05-Two-Heaps-Pattern/5.1-Two-Heaps-Overview.md) | [K-Way Merge](../06-K-Way-Merge-Pattern/6.1-K-Way-Merge-Overview.md)
- **Graph Algorithms:** Dijkstra | Prim | A*
