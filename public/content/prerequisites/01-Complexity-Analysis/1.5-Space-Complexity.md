# 1.5 Space Complexity

> **How to analyze and optimize memory usage in your algorithms.**
>
> ‚è±Ô∏è *Estimated reading: 20 minutes*

---

## üéØ Why Space Complexity Matters

Memory is a **finite resource**. Understanding space complexity helps you:

1. **Avoid crashes** ‚Äî Running out of memory kills your program
2. **Write efficient code** ‚Äî Less memory often means faster execution (cache locality)
3. **Pass interviews** ‚Äî You'll always be asked about both time AND space
4. **Make trade-offs** ‚Äî Sometimes you trade space for time, or vice versa

---

## üìê What Is Space Complexity?

Space complexity measures **how much additional memory** your algorithm needs relative to input size.

### Two Types of Space

| Type | What It Counts | Example |
|------|---------------|---------|
| **Auxiliary Space** | Extra space used by the algorithm (excluding input) | Variables, data structures, call stack |
| **Total Space** | Auxiliary space + input space | Everything |

**In interviews, we usually discuss auxiliary space** unless otherwise specified.

---

## üü¢ O(1) ‚Äî Constant Space

### What It Means

The algorithm uses a **fixed amount of memory** regardless of input size.

```python
def find_max(arr):
    """O(1) space - only uses a single variable."""
    max_val = arr[0]          # 1 variable
    for element in arr:       # 1 loop variable
        if element > max_val:
            max_val = element
    return max_val
    # Total: 2 variables = O(1) space
```

```javascript
function findMax(arr) {
    let maxVal = arr[0];
    for (const element of arr) {
        if (element > maxVal) {
            maxVal = element;
        }
    }
    return maxVal;
}
```

### Common O(1) Space Patterns

| Pattern | Example |
|---------|---------|
| Using a few variables | `left, right = 0, len(arr) - 1` |
| In-place modification | Swap elements without extra array |
| Two pointers | Pointers don't grow with input |
| Sliding window (fixed size) | Window variables only |

### Example: Two Sum with O(1) Space (Sorted Array)

```python
def two_sum_sorted(arr, target):
    """O(1) space using two pointers."""
    left, right = 0, len(arr) - 1
    
    while left < right:
        current_sum = arr[left] + arr[right]
        if current_sum == target:
            return [left, right]
        elif current_sum < target:
            left += 1
        else:
            right -= 1
    
    return [-1, -1]
    # Space: O(1) - only two pointers
```

---

## üü° O(n) ‚Äî Linear Space

### What It Means

Memory usage grows **proportionally** with input size.

```python
def reverse_array(arr):
    """O(n) space - creates a new array of same size."""
    result = []               # Will hold n elements
    for element in arr:
        result.insert(0, element)
    return result
    # Space: O(n) for the result array
```

```python
def count_frequency(arr):
    """O(n) space - hash map can hold up to n unique elements."""
    freq = {}                 # Dictionary grows with unique elements
    for element in arr:
        freq[element] = freq.get(element, 0) + 1
    return freq
    # Space: O(n) in worst case (all unique elements)
```

### Common O(n) Space Patterns

| Pattern | Why O(n) |
|---------|----------|
| Creating a copy | `new_arr = arr.copy()` |
| Hash map/set | Storing up to n elements |
| Stack/Queue | Could hold n elements |
| Result array | Building output of size n |
| Recursion (linear) | n stack frames |

### Example: Two Sum with O(n) Space (Hash Map)

```python
def two_sum(arr, target):
    """O(n) space using hash map for O(1) lookups."""
    seen = {}                 # Stores up to n elements
    
    for i, num in enumerate(arr):
        complement = target - num
        if complement in seen:
            return [seen[complement], i]
        seen[num] = i
    
    return [-1, -1]
    # Space: O(n) for the hash map
```

---

## üî¥ O(n¬≤) ‚Äî Quadratic Space

### What It Means

Memory usage grows with the **square** of input size.

```python
def create_adjacency_matrix(n):
    """O(n¬≤) space - 2D matrix."""
    matrix = [[0] * n for _ in range(n)]
    # n rows √ó n columns = n¬≤ cells
    return matrix
```

```python
def all_pairs(arr):
    """O(n¬≤) space - storing all pairs."""
    pairs = []
    for i in range(len(arr)):
        for j in range(len(arr)):
            pairs.append((arr[i], arr[j]))  # n¬≤ pairs
    return pairs
```

### When O(n¬≤) Space Is Acceptable

| Situation | Example |
|-----------|---------|
| Dynamic Programming (2D table) | Longest Common Subsequence |
| Graph adjacency matrix | Dense graphs |
| Matrix operations | Matrix multiplication |
| All-pairs problems | Floyd-Warshall |

---

## üìö Recursion and Stack Space

### The Hidden Cost

Every recursive call adds a **stack frame** to memory:

```python
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)
```

**Memory visualization:**
```
factorial(5)  ‚Üí Stack: [f(5)]
factorial(4)  ‚Üí Stack: [f(5), f(4)]
factorial(3)  ‚Üí Stack: [f(5), f(4), f(3)]
factorial(2)  ‚Üí Stack: [f(5), f(4), f(3), f(2)]
factorial(1)  ‚Üí Stack: [f(5), f(4), f(3), f(2), f(1)]
              ‚Üê Stack unwinds as calls return
```

**Space complexity:** O(n) ‚Äî n stack frames

### Recursion Space Analysis

| Recursion Type | Stack Depth | Space |
|----------------|-------------|-------|
| Linear (T(n-1)) | n | O(n) |
| Divide by 2 (T(n/2)) | log n | O(log n) |
| Binary (2 √ó T(n/2)) | log n | O(log n) |
| Binary (2 √ó T(n-1)) | n | O(n) |

### Example: Binary Search Space

```python
def binary_search(arr, target, left, right):
    if left > right:
        return -1
    
    mid = (left + right) // 2
    
    if arr[mid] == target:
        return mid
    elif arr[mid] < target:
        return binary_search(arr, target, mid + 1, right)
    else:
        return binary_search(arr, target, left, mid - 1)
    
    # Time: O(log n)
    # Space: O(log n) - call stack depth
```

**Iterative version (O(1) space):**
```python
def binary_search_iterative(arr, target):
    left, right = 0, len(arr) - 1
    
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    
    return -1
    # Time: O(log n)
    # Space: O(1) - no recursion!
```

---

## ‚öñÔ∏è Space-Time Trade-offs

Often, you can trade space for time (or vice versa):

### Example 1: Two Sum

| Approach | Time | Space | Trade-off |
|----------|------|-------|-----------|
| Brute force (nested loops) | O(n¬≤) | O(1) | Slow, but no extra memory |
| Hash map | O(n) | O(n) | Fast, but uses more memory |
| Sort + two pointers | O(n log n) | O(1)* | Balanced |

*If sorting is in-place; otherwise O(n) for the sorted copy.

### Example 2: Fibonacci

| Approach | Time | Space | Trade-off |
|----------|------|-------|-----------|
| Naive recursion | O(2‚Åø) | O(n) | Terrible time, moderate space |
| Memoization | O(n) | O(n) | Great time, uses memo table |
| Tabulation | O(n) | O(n) | Same as memoization |
| Space-optimized | O(n) | O(1) | Only track last 2 values |

```python
# O(n) time, O(n) space - tabulation
def fib_table(n):
    if n <= 1:
        return n
    dp = [0] * (n + 1)
    dp[1] = 1
    for i in range(2, n + 1):
        dp[i] = dp[i-1] + dp[i-2]
    return dp[n]

# O(n) time, O(1) space - optimized
def fib_optimized(n):
    if n <= 1:
        return n
    prev, curr = 0, 1
    for _ in range(2, n + 1):
        prev, curr = curr, prev + curr
    return curr
```

### Example 3: Sorting

| Algorithm | Time (Avg) | Space | Notes |
|-----------|------------|-------|-------|
| Merge Sort | O(n log n) | O(n) | Needs auxiliary array |
| Quick Sort | O(n log n) | O(log n) | In-place (stack space only) |
| Heap Sort | O(n log n) | O(1) | In-place |

---

## üîç Analyzing Space: Step by Step

### Step 1: Identify Variables

```python
def example(arr):
    n = len(arr)        # O(1) - single integer
    total = 0           # O(1) - single integer
    seen = set()        # O(?) - depends on how many elements added
    result = []         # O(?) - depends on how many elements added
```

### Step 2: Track How Data Structures Grow

```python
def example(arr):
    seen = set()        
    for x in arr:
        seen.add(x)     # Adds up to n unique elements ‚Üí O(n)
    
    result = []
    for x in arr:
        if x > 0:
            result.append(x)  # Could be all elements ‚Üí O(n)
```

### Step 3: Consider Recursion Stack

```python
def example(arr, i=0):
    if i >= len(arr):
        return 0
    return arr[i] + example(arr, i + 1)  # n calls deep ‚Üí O(n) stack
```

### Step 4: Take the Maximum

```python
def complex_example(arr):
    # Phase 1: O(n) for hash map
    freq = {}
    for x in arr:
        freq[x] = freq.get(x, 0) + 1
    
    # Phase 2: O(n) for result list
    result = [x for x in arr if freq[x] > 1]
    
    # Space: max(O(n), O(n)) = O(n)
    return result
```

---

## ‚ö†Ô∏è Common Space Mistakes

### Mistake 1: Forgetting Slicing Creates Copies

```python
def process(arr):
    left_half = arr[:len(arr)//2]   # Creates new array! O(n/2) = O(n)
    right_half = arr[len(arr)//2:]  # Creates new array! O(n/2) = O(n)
    # Total extra space: O(n)
```

**Fix:** Use indices instead:
```python
def process(arr, start, end):
    mid = (start + end) // 2
    # Work with arr[start:mid] and arr[mid:end] using indices
    # No new arrays created!
```

### Mistake 2: Ignoring String Operations

In Python, strings are **immutable**. Concatenation creates new strings:

```python
def bad_concat(strings):
    result = ""
    for s in strings:
        result += s    # Creates new string each time! O(n¬≤) total
    return result
```

**Fix:** Use `join()`:
```python
def good_concat(strings):
    return "".join(strings)  # O(n) total
```

### Mistake 3: Forgetting Recursion Stack

```python
def sum_array(arr, i=0):
    if i >= len(arr):
        return 0
    return arr[i] + sum_array(arr, i + 1)
    # Looks O(1) but has O(n) stack space!
```

### Mistake 4: Not Counting Built-in Operations

```python
def example(arr):
    sorted_arr = sorted(arr)  # Creates new array! O(n) space
    reversed_arr = list(reversed(arr))  # Creates new array! O(n) space
```

**In-place alternatives:**
```python
def example_in_place(arr):
    arr.sort()       # Sorts in place, O(1) extra space
    arr.reverse()    # Reverses in place, O(1) extra space
```

---

## üìä Quick Reference: Common Algorithm Space

| Algorithm/Operation | Time | Space | Notes |
|---------------------|------|-------|-------|
| **Arrays** |
| Binary Search | O(log n) | O(1) | Iterative |
| Two Pointers | O(n) | O(1) | In-place |
| Sliding Window | O(n) | O(k) | k = window size |
| Prefix Sum | O(n) | O(n) | Stores prefix array |
| **Sorting** |
| Bubble/Selection/Insertion | O(n¬≤) | O(1) | In-place |
| Merge Sort | O(n log n) | O(n) | Needs aux array |
| Quick Sort | O(n log n) | O(log n) | Stack space |
| Heap Sort | O(n log n) | O(1) | In-place |
| Counting Sort | O(n + k) | O(k) | k = range of values |
| **Recursion** |
| Factorial | O(n) | O(n) | Stack depth |
| Binary Search (recursive) | O(log n) | O(log n) | Stack depth |
| Merge Sort | O(n log n) | O(n + log n) | Array + stack |
| Tree Traversal | O(n) | O(h) | h = tree height |
| **Data Structures** |
| Hash Map | O(1) avg | O(n) | Stores n elements |
| Stack/Queue | O(1) | O(n) | Stores n elements |
| Heap | O(log n) | O(n) | Stores n elements |
| Graph (Adj List) | varies | O(V + E) | Vertices + edges |
| Graph (Adj Matrix) | varies | O(V¬≤) | V√óV matrix |

---

## üé§ Interview Communication

When discussing space complexity:

### Template 1: Simple Case

> "The space complexity is O(1) because we only use a constant number of variables regardless of input size."

### Template 2: With Data Structure

> "The space complexity is O(n) because our hash map could store up to n unique elements in the worst case."

### Template 3: With Recursion

> "The space complexity is O(log n) due to the recursion stack. Each call halves the problem, so we have at most log n frames on the stack simultaneously."

### Template 4: Trade-off Discussion

> "We have two options: O(1) space with O(n¬≤) time using brute force, or O(n) space with O(n) time using a hash map. Given the constraints, I'll use the hash map approach since time is usually more critical."

---

## üìù Practice Problems

### Problem 1: What's the space complexity?

```python
def mystery(n):
    arr = [0] * n
    for i in range(n):
        arr[i] = i * 2
    return arr
```

<details>
<summary><strong>Answer</strong></summary>

**O(n)** ‚Äî We create an array of size n.

</details>

### Problem 2: What's the space complexity?

```python
def mystery(arr):
    left, right = 0, len(arr) - 1
    while left < right:
        arr[left], arr[right] = arr[right], arr[left]
        left += 1
        right -= 1
```

<details>
<summary><strong>Answer</strong></summary>

**O(1)** ‚Äî Only using two pointer variables, modifying in-place.

</details>

### Problem 3: What's the space complexity?

```python
def mystery(n):
    if n <= 0:
        return
    mystery(n // 2)
    mystery(n // 2)
```

<details>
<summary><strong>Answer</strong></summary>

**O(log n)** ‚Äî The recursion depth is log n. Even though there are 2 calls, they don't exist on the stack at the same time (one completes before the other starts).

</details>

---

> **üí° Key Insight:** Space complexity is often overlooked but crucial for large-scale systems. An O(n) algorithm that uses O(n¬≤) space might be worse than an O(n¬≤) algorithm that uses O(1) space when memory is the bottleneck.

---

**Next:** [1.6 Complexity Cheatsheet](./1.6-Complexity-Cheatsheet.md) ‚Üí
