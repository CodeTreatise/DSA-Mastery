# 8.1 LRU Cache (LC 146)

> **Grokking Pattern:** Hash Map + Doubly Linked List
>
> **Difficulty:** Medium | **Frequency:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê One of the Most Common Interview Questions

---

## Problem Statement

Design a data structure that follows the constraints of a **Least Recently Used (LRU) cache**.

Implement the `LRUCache` class:
- `LRUCache(int capacity)` - Initialize with positive capacity
- `int get(int key)` - Return value if key exists, else -1
- `void put(int key, int value)` - Update or insert. If at capacity, evict the least recently used item.

**Both `get` and `put` must run in O(1) average time complexity.**

```
Input:
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]

Output:
[null, null, null, 1, null, -1, null, -1, 3, 4]

Explanation:
LRUCache(2)     // capacity = 2
put(1, 1)       // cache: {1=1}
put(2, 2)       // cache: {1=1, 2=2}
get(1)          // returns 1, cache: {2=2, 1=1} (1 is now most recent)
put(3, 3)       // evicts key 2, cache: {1=1, 3=3}
get(2)          // returns -1 (not found)
put(4, 4)       // evicts key 1, cache: {3=3, 4=4}
get(1)          // returns -1 (not found)
get(3)          // returns 3
get(4)          // returns 4
```

[LeetCode 146 - LRU Cache](https://leetcode.com/problems/lru-cache/)

---

## üéØ Pattern Recognition

<details>
<summary><strong>How to Identify This Pattern</strong></summary>

**Look for these signals:**
- Need O(1) get AND O(1) update/insert
- Need to track "recency" or "order of access"
- Need to efficiently remove least/most recently used

**Keywords:**
- "cache", "LRU", "MRU", "recently used"
- "eviction policy", "fixed capacity"

**Why this data structure combination:**
- **Hash Map**: O(1) lookup by key
- **Doubly Linked List**: O(1) remove from anywhere + O(1) add to front/back

</details>

---

## ‚úÖ When to Use This Pattern

- Implementing any cache with eviction policy
- Web browser cache
- Database query cache
- Operating system page replacement
- Any "most/least recently used" tracking

---

## ‚ùå When NOT to Use

| Situation | Why Not | Use Instead |
|-----------|---------|-------------|
| LFU (frequency-based) | Different eviction policy | Two hash maps + linked list |
| No capacity limit | Simpler structure | Just hash map |
| FIFO eviction | No recency tracking | Queue |
| Random eviction | No order needed | Array + random |

---

## üîó Concept Map

<details>
<summary><strong>Prerequisites & Next Steps</strong></summary>

**Before this, you should know:**
- [Hash Maps](../../09-Hashing.md)
- [Doubly Linked List](../02-Doubly-LL/2.1-Doubly-LL-Complete.md)

**After mastering this:**
- [LFU Cache](https://leetcode.com/problems/lfu-cache/) - LC 460 (harder)
- Design Twitter
- Browser history implementation

**Combines:**
- Hash Map for O(1) key lookup
- DLL for O(1) position updates

</details>

---

## üìê How It Works

### Data Structure Design

```
Hash Map: key ‚Üí Node (for O(1) lookup)
Doubly Linked List: tracks recency (head = most recent, tail = least recent)

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Hash Map                          ‚îÇ
‚îÇ  key=1 ‚Üí Node1    key=3 ‚Üí Node3    key=4 ‚Üí Node4    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì           ‚Üì            ‚Üì
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ      Doubly Linked List       ‚îÇ
  head ‚Üê‚Üí  ‚îÇ  [1] ‚Üê‚Üí [3] ‚Üê‚Üí [4]           ‚îÇ ‚Üê‚Üí tail
           ‚îÇ  MRU          LRU            ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Operations

| Operation | Steps | Time |
|-----------|-------|------|
| `get(key)` | Look up in hash map ‚Üí move node to front |" O(1) "|
| `put(key, val)` | If exists: update + move to front. If new: add to front, evict if full |" O(1) "|

---

## üíª Code Implementation

### Complete Solution with Sentinel Nodes

**Python:**

```python
class DLLNode:
    """Node for doubly linked list."""
    def __init__(self, key=0, val=0):
        self.key = key  # Need key for eviction (to remove from hash map)
        self.val = val
        self.prev = None
        self.next = None


class LRUCache:
    """
    LRU Cache using Hash Map + Doubly Linked List.
    
    Hash Map: key ‚Üí node (O(1) lookup)
    DLL: head = MRU, tail = LRU (O(1) remove/add)
    
    Time: O(1) for get and put
    Space: O(capacity)
    """
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = {}  # key ‚Üí DLLNode
        
        # Sentinel nodes (dummy head and tail)
        self.head = DLLNode()  # Most Recently Used side
        self.tail = DLLNode()  # Least Recently Used side
        self.head.next = self.tail
        self.tail.prev = self.head
    
    def _remove(self, node: DLLNode) -> None:
        """Remove node from its current position in DLL."""
        prev_node = node.prev
        next_node = node.next
        prev_node.next = next_node
        next_node.prev = prev_node
    
    def _add_to_front(self, node: DLLNode) -> None:
        """Add node right after head (most recently used position)."""
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def _move_to_front(self, node: DLLNode) -> None:
        """Move existing node to front (just accessed)."""
        self._remove(node)
        self._add_to_front(node)
    
    def _evict_lru(self) -> None:
        """Remove least recently used item (node before tail)."""
        lru_node = self.tail.prev
        self._remove(lru_node)
        del self.cache[lru_node.key]  # Also remove from hash map!
    
    def get(self, key: int) -> int:
        """
        Get value by key. Return -1 if not found.
        Also moves the accessed item to front (most recently used).
        """
        if key not in self.cache:
            return -1
        
        node = self.cache[key]
        self._move_to_front(node)  # Mark as recently used
        return node.val
    
    def put(self, key: int, value: int) -> None:
        """
        Insert or update key-value pair.
        If at capacity, evict least recently used item first.
        """
        if key in self.cache:
            # Update existing
            node = self.cache[key]
            node.val = value
            self._move_to_front(node)
        else:
            # Insert new
            if len(self.cache) >= self.capacity:
                self._evict_lru()
            
            new_node = DLLNode(key, value)
            self.cache[key] = new_node
            self._add_to_front(new_node)
```

**JavaScript:**

```javascript
class DLLNode {
    constructor(key = 0, val = 0) {
        this.key = key;
        this.val = val;
        this.prev = null;
        this.next = null;
    }
}

class LRUCache {
    constructor(capacity) {
        this.capacity = capacity;
        this.cache = new Map();  // key ‚Üí DLLNode
        
        // Sentinel nodes
        this.head = new DLLNode();
        this.tail = new DLLNode();
        this.head.next = this.tail;
        this.tail.prev = this.head;
    }
    
    _remove(node) {
        const prevNode = node.prev;
        const nextNode = node.next;
        prevNode.next = nextNode;
        nextNode.prev = prevNode;
    }
    
    _addToFront(node) {
        node.prev = this.head;
        node.next = this.head.next;
        this.head.next.prev = node;
        this.head.next = node;
    }
    
    _moveToFront(node) {
        this._remove(node);
        this._addToFront(node);
    }
    
    _evictLRU() {
        const lruNode = this.tail.prev;
        this._remove(lruNode);
        this.cache.delete(lruNode.key);
    }
    
    get(key) {
        if (!this.cache.has(key)) {
            return -1;
        }
        
        const node = this.cache.get(key);
        this._moveToFront(node);
        return node.val;
    }
    
    put(key, value) {
        if (this.cache.has(key)) {
            const node = this.cache.get(key);
            node.val = value;
            this._moveToFront(node);
        } else {
            if (this.cache.size >= this.capacity) {
                this._evictLRU();
            }
            
            const newNode = new DLLNode(key, value);
            this.cache.set(key, newNode);
            this._addToFront(newNode);
        }
    }
}
```

### Using Python's OrderedDict (Shortcut)

```python
from collections import OrderedDict

class LRUCacheSimple:
    """
    LRU Cache using OrderedDict.
    OrderedDict maintains insertion order and has O(1) move_to_end.
    
    Note: This is a shortcut - interviewers may ask for manual implementation!
    """
    
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = OrderedDict()
    
    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        
        self.cache.move_to_end(key)  # Mark as recently used
        return self.cache[key]
    
    def put(self, key: int, value: int) -> None:
        if key in self.cache:
            self.cache.move_to_end(key)
        
        self.cache[key] = value
        
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)  # Remove oldest (first)
```

---

## ‚ö° Complexity Analysis

| Operation | Time | Space | Notes |
|-----------|------|-------|-------|
| `get` |" O(1) "| O(1) | Hash lookup + DLL reorder |
| `put` |" O(1) "| O(1) | Hash insert + DLL add |
| Overall space | - |" O(capacity) "| Stores up to capacity items |

**Why O(1) for all operations:**
- Hash map: O(1) lookup, insert, delete
- DLL with sentinel nodes: O(1) add/remove anywhere
- We store node references in hash map, not positions

---

## üîÑ Variations

| Variation | Difference | Use Case |
|-----------|------------|----------|
| LFU Cache | Evict least frequently used | Different access patterns |
| MRU Cache | Evict most recently used | Specific use cases |
| Time-based expiry | Evict after TTL | Web caching |
| Size-based (bytes) | Track memory usage | Memory management |

---

## ‚ö†Ô∏è Common Mistakes

### 1. Forgetting to Store Key in Node

```python
# ‚ùå Wrong - can't evict from hash map without key
class Node:
    def __init__(self, val):
        self.val = val  # No key!

# When evicting, how do we know which key to delete from cache?

# ‚úÖ Correct - store both key and value
class Node:
    def __init__(self, key, val):
        self.key = key  # Needed for eviction!
        self.val = val
```

### 2. Not Moving to Front on GET

```python
# ‚ùå Wrong - get doesn't update recency
def get(self, key):
    if key in self.cache:
        return self.cache[key].val  # Didn't move to front!

# ‚úÖ Correct - move to front after access
def get(self, key):
    if key in self.cache:
        node = self.cache[key]
        self._move_to_front(node)  # Mark as recently used!
        return node.val
```

### 3. Evicting Before Checking Capacity

```python
# ‚ùå Wrong - evicts even when updating existing key
def put(self, key, value):
    if len(self.cache) >= self.capacity:
        self._evict_lru()  # Wrong! Key might already exist
    # ... rest

# ‚úÖ Correct - only evict when adding NEW key at capacity
def put(self, key, value):
    if key in self.cache:
        # Update existing - no eviction needed
        ...
    else:
        if len(self.cache) >= self.capacity:
            self._evict_lru()  # Only when adding new at capacity
        # ... add new
```

---

## üìù Practice Problems (Progressive)

### Medium (This problem)
- [ ] [LRU Cache](https://leetcode.com/problems/lru-cache/) - LC 146 ‚≠ê‚≠ê‚≠ê

### Hard (Extensions)
- [ ] [LFU Cache](https://leetcode.com/problems/lfu-cache/) - LC 460
- [ ] [Design In-Memory File System](https://leetcode.com/problems/design-in-memory-file-system/) - LC 588

### Related Design Problems
- [ ] [Design Twitter](https://leetcode.com/problems/design-twitter/) - LC 355
- [ ] [Design Browser History](https://leetcode.com/problems/design-browser-history/) - LC 1472

<details>
<summary><strong>üß† Spaced Repetition Schedule</strong></summary>

- **Day 1:** Implement from scratch without reference
- **Day 3:** Implement again, focus on edge cases
- **Day 7:** Code review - check all O(1) operations
- **Day 14:** Extend to LFU Cache
- **Day 30:** System design: where would you use LRU Cache?

</details>

---

## üé§ Interview Context

<details>
<summary><strong>How to Communicate This in Interviews</strong></summary>

**Opening statement:**
> "For O(1) get and put, I'll use a hash map for lookups and a doubly linked list for maintaining recency order."

**Explain the structure:**
> "The hash map stores key ‚Üí node, giving O(1) access. The DLL tracks recency - head is most recent, tail is least recent. Moving a node is O(1) in DLL."

**Why DLL, not singly linked?**
> "With DLL, I can remove any node in O(1) because I have access to its previous node. Singly linked would be O(n) to find the predecessor."

**Why sentinel nodes?**
> "Dummy head and tail eliminate edge cases when the list is empty or when removing the first/last real node."

**Common follow-ups:**
- "What about thread safety?" ‚Üí Use locks or concurrent data structures
- "How would you handle distributed cache?" ‚Üí Consistent hashing
- "What about LFU?" ‚Üí Additional frequency tracking needed

</details>

**Company Focus:**

| Company | Frequency | Notes |
|---------|-----------|-------|
| Amazon | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | One of the most asked |
| Meta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Very common |
| Google | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | May lead to system design |
| Microsoft | ‚≠ê‚≠ê‚≠ê‚≠ê | Classic design question |
| Apple | ‚≠ê‚≠ê‚≠ê‚≠ê | Implementation focused |

---

## ‚è±Ô∏è Time Estimates

| Activity | Time | Notes |
|----------|------|-------|
| Understand | 5-7 min | Core concept |
| Design discussion | 5-10 min | Data structure choice |
| Implement | 15-20 min | Full solution |
| Test edge cases | 5-7 min | Capacity 1, updates, etc. |
| Interview target | 30-35 min | Including discussion |

---

> **üí° Key Insight:** The magic of LRU Cache is combining two data structures: Hash Map for O(1) lookup and DLL for O(1) order updates. Neither alone can achieve O(1) for both operations. Store the NODE in the hash map, not just the value, so you can directly manipulate the DLL.

---

## üîó Related

- [Doubly Linked List](../02-Doubly-LL/2.1-Doubly-LL-Complete.md) - Foundation
- [Hash Maps](../../09-Hashing.md) - O(1) lookup
- [LFU Cache](https://leetcode.com/problems/lfu-cache/) - LC 460, harder variant
